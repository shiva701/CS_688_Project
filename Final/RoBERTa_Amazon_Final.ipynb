{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9yiifL5wZ4C"
      },
      "source": [
        "# Loading Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0-gsmwhwZ4E"
      },
      "source": [
        "Doing some experimentations I notice that there was a CUDA error coming with older version of PyTorch, so it's advisable to upgrade PyTorch version."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzehLcpzwZ4F",
        "outputId": "9242dacd-0d75-4be5-dfcf-41fdfa284e61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.12.1+cu113)\n",
            "Collecting torch\n",
            "  Downloading torch-1.13.0-cp37-cp37m-manylinux1_x86_64.whl (890.2 MB)\n",
            "\u001b[K     |██████████████████████████████  | 834.1 MB 115.4 MB/s eta 0:00:01tcmalloc: large alloc 1147494400 bytes == 0x64f10000 @  0x7fc946cd5615 0x58ead6 0x4f355e 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x510325 0x5b4ee6 0x58ff2e 0x50d482 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4bac0a 0x538a76 0x590ae5 0x510280 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50c4fc 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e\n",
            "\u001b[K     |████████████████████████████████| 890.2 MB 6.6 kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 557.1 MB 9.6 kB/s \n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 317.1 MB 36 kB/s \n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 21.0 MB 81.0 MB/s \n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[K     |████████████████████████████████| 849 kB 83.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (57.4.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\n",
            "Installing collected packages: nvidia-cublas-cu11, nvidia-cudnn-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.1+cu113\n",
            "    Uninstalling torch-1.12.1+cu113:\n",
            "      Successfully uninstalled torch-1.12.1+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.13.1+cu113 requires torch==1.12.1, but you have torch 1.13.0 which is incompatible.\n",
            "torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.13.0 which is incompatible.\n",
            "torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.13.0 which is incompatible.\u001b[0m\n",
            "Successfully installed nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 torch-1.13.0\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbNgyDqzwZ4G",
        "outputId": "a65ce443-2ea8-49e9-c1c9-f8d63586daf4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5 MB 28.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.0-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 88.4 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 81.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.0 tokenizers-0.13.2 transformers-4.24.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RdLBxD98wZ4H"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import random\n",
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from transformers import RobertaTokenizerFast, RobertaForSequenceClassification\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i06kd8rvwZ4I",
        "outputId": "fff87438-29be-457e-fef1-d557cd8cb50d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: A100-SXM4-40GB\n"
          ]
        }
      ],
      "source": [
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_tfnIWPC0mF"
      },
      "source": [
        "# Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rx-xRH9IuK87",
        "outputId": "ad5e0559-9617-4a52-a973-946e22442704"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHpohSmgwLjP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/CS-688_Project/Amazon/train.csv\", header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rpi5rlNv0wzp",
        "outputId": "776df7e4-ef75-43b2-b3f1-0167613621b5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3600000, 3)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aThuh2xL9bXf"
      },
      "outputs": [],
      "source": [
        "izuo1 = data.loc[data[0] == 1]\n",
        "izuo2 = data.loc[data[0] == 2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grOPGGKM9dHH"
      },
      "outputs": [],
      "source": [
        "train1 = izuo1[:100000]\n",
        "train2 = izuo2[:100000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_DlUzcn9dJz"
      },
      "outputs": [],
      "source": [
        "train1 = train1.reset_index(drop=True)\n",
        "train2 = train2.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nicHBAbh9dMb"
      },
      "outputs": [],
      "source": [
        "#concading tran1 and train2\n",
        "frames = [train1, train2]\n",
        "data = pd.concat(frames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u03JB-pD9hmt"
      },
      "outputs": [],
      "source": [
        "data = data.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RrnqvTzl92wY"
      },
      "outputs": [],
      "source": [
        "data = data.drop(columns=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "p-AcIIlO97jp",
        "outputId": "bf504600-d8d7-4eff-f458-f75803e59e49"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a2e726f5-db03-4365-8329-5496c0e7d3b1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>This is a self-published book, and if you want...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>A complete waste of time. Typographical errors...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>I guess you have to be a romance novel lover f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>I feel I have to write to keep others from was...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>It's glaringly obvious that all of the glowing...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199995</th>\n",
              "      <td>2</td>\n",
              "      <td>Dr. Harvey Karp has come up with a way to help...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199996</th>\n",
              "      <td>2</td>\n",
              "      <td>We are expecting our first child and this book...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199997</th>\n",
              "      <td>2</td>\n",
              "      <td>We got this book upon a recommendation from an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199998</th>\n",
              "      <td>2</td>\n",
              "      <td>I enjoyed this book and suggest reading it BEF...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199999</th>\n",
              "      <td>2</td>\n",
              "      <td>Great book! It takes things you may already kn...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a2e726f5-db03-4365-8329-5496c0e7d3b1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a2e726f5-db03-4365-8329-5496c0e7d3b1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a2e726f5-db03-4365-8329-5496c0e7d3b1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        0                                                  2\n",
              "0       1  This is a self-published book, and if you want...\n",
              "1       1  A complete waste of time. Typographical errors...\n",
              "2       1  I guess you have to be a romance novel lover f...\n",
              "3       1  I feel I have to write to keep others from was...\n",
              "4       1  It's glaringly obvious that all of the glowing...\n",
              "...    ..                                                ...\n",
              "199995  2  Dr. Harvey Karp has come up with a way to help...\n",
              "199996  2  We are expecting our first child and this book...\n",
              "199997  2  We got this book upon a recommendation from an...\n",
              "199998  2  I enjoyed this book and suggest reading it BEF...\n",
              "199999  2  Great book! It takes things you may already kn...\n",
              "\n",
              "[200000 rows x 2 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCRhKOoNwgte"
      },
      "source": [
        "# Processing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "68wPXZI4R9Ox",
        "outputId": "75774595-650f-4cba-cc69-039fd74fd8c5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3c5422d3-7d90-454f-b36e-4bd03f8c5743\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>This is a self-published book, and if you want...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>A complete waste of time. Typographical errors...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>I guess you have to be a romance novel lover f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>I feel I have to write to keep others from was...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>It's glaringly obvious that all of the glowing...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199995</th>\n",
              "      <td>2</td>\n",
              "      <td>Dr. Harvey Karp has come up with a way to help...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199996</th>\n",
              "      <td>2</td>\n",
              "      <td>We are expecting our first child and this book...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199997</th>\n",
              "      <td>2</td>\n",
              "      <td>We got this book upon a recommendation from an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199998</th>\n",
              "      <td>2</td>\n",
              "      <td>I enjoyed this book and suggest reading it BEF...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199999</th>\n",
              "      <td>2</td>\n",
              "      <td>Great book! It takes things you may already kn...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c5422d3-7d90-454f-b36e-4bd03f8c5743')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3c5422d3-7d90-454f-b36e-4bd03f8c5743 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3c5422d3-7d90-454f-b36e-4bd03f8c5743');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        sentiment                                             review\n",
              "0               1  This is a self-published book, and if you want...\n",
              "1               1  A complete waste of time. Typographical errors...\n",
              "2               1  I guess you have to be a romance novel lover f...\n",
              "3               1  I feel I have to write to keep others from was...\n",
              "4               1  It's glaringly obvious that all of the glowing...\n",
              "...           ...                                                ...\n",
              "199995          2  Dr. Harvey Karp has come up with a way to help...\n",
              "199996          2  We are expecting our first child and this book...\n",
              "199997          2  We got this book upon a recommendation from an...\n",
              "199998          2  I enjoyed this book and suggest reading it BEF...\n",
              "199999          2  Great book! It takes things you may already kn...\n",
              "\n",
              "[200000 rows x 2 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.rename(columns = {0:'sentiment', 2:'review'}, inplace = True)\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYW46GUXurbB"
      },
      "outputs": [],
      "source": [
        "df=data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "vIrByRkgwgth",
        "outputId": "fcf5136e-07de-4ed9-acc5-32e0e248c251"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAesAAAE/CAYAAABmXOuYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAUbklEQVR4nO3df6xfd13H8efLlfFLYR2tc7YbnaERC9EwmlHFIDKzdfNHZ4JkC7JmWWgiQ9EYdaihyXAJJsbpEpgurLIpMpcBrsHO0mwQ4o/O3bHJfgG7DHBtBqvr2PihYuHtH99P9Wt37+3t/bb3+/ne+3wk39xz3p/POd/Pp9977uue09PTVBWSJKlf3zPuAUiSpLkZ1pIkdc6wliSpc4a1JEmdM6wlSeqcYS1JUudWjHsAx9uqVatq3bp14x6GJEnH5J577vn3qlo9U9uSC+t169YxNTU17mFIknRMknx5tjYvg0uS1DnDWpKkzhnWkiR1zrCWJKlzhrUkSZ0zrCVJ6pxhLUlS5wxrSZI6d9SwTrIjyRNJHhiqnZpkT5JH2teVrZ4k1yaZTvKZJGcPbbO19X8kydah+quT3N+2uTZJ5noPSZKWm/mcWX8A2HxE7UrgjqpaD9zR1gEuANa31zbgOhgEL7AdeA1wDrB9KHyvA946tN3mo7yHJEnLylHDuqo+BRw8orwFuLEt3whcNFS/qQb2AqckOR04H9hTVQer6ilgD7C5tb2oqvZWVQE3HbGvmd5DkqRlZaF/Z31aVT3elr8CnNaW1wCPDfXb12pz1ffNUJ/rPSRJWlZG/o88qqqS1PEYzELfI8k2BpfdOfPMM4/b+179V586bvuSFtPv/fLrxj2EY+Kxpkm0mMfZQs+sv9ouYdO+PtHq+4EzhvqtbbW56mtnqM/1Hs9SVddX1caq2rh69Yz/u5gkSRNroWG9Ezh8R/dW4Lah+qXtrvBNwNPtUvZu4LwkK9uNZecBu1vbM0k2tbvALz1iXzO9hyRJy8pRL4Mn+RDwemBVkn0M7up+D3BLksuBLwNvat13ARcC08C3gMsAqupgkncDd7d+V1XV4ZvW3sbgjvPnA7e3F3O8hyRJy8pRw7qqLpml6dwZ+hZwxSz72QHsmKE+BbxyhvqTM72HJEnLjU8wkySpc4a1JEmdM6wlSeqcYS1JUucMa0mSOmdYS5LUOcNakqTOGdaSJHXOsJYkqXOGtSRJnTOsJUnqnGEtSVLnDGtJkjpnWEuS1DnDWpKkzhnWkiR1zrCWJKlzhrUkSZ0zrCVJ6pxhLUlS5wxrSZI6Z1hLktQ5w1qSpM4Z1pIkdc6wliSpc4a1JEmdM6wlSeqcYS1JUucMa0mSOmdYS5LUOcNakqTOGdaSJHXOsJYkqXOGtSRJnTOsJUnqnGEtSVLnDGtJkjpnWEuS1DnDWpKkzhnWkiR1zrCWJKlzhrUkSZ0zrCVJ6pxhLUlS5wxrSZI6Z1hLktS5kcI6yW8keTDJA0k+lOR5Sc5KcleS6SR/k+Tk1ve5bX26ta8b2s87W/1zSc4fqm9utekkV44yVkmSJtWCwzrJGuDXgI1V9UrgJOBi4A+Ba6rqZcBTwOVtk8uBp1r9mtaPJBvadq8ANgPvS3JSkpOA9wIXABuAS1pfSZKWlVEvg68Anp9kBfAC4HHgDcCtrf1G4KK2vKWt09rPTZJWv7mq/quqvghMA+e013RVPVpV3wZubn0lSVpWFhzWVbUf+CPg3xiE9NPAPcDXqupQ67YPWNOW1wCPtW0Ptf4vGa4fsc1s9WdJsi3JVJKpAwcOLHRKkiR1aZTL4CsZnOmeBfwg8EIGl7EXXVVdX1Ubq2rj6tWrxzEESZJOmFEug/8M8MWqOlBV/w18BHgtcEq7LA6wFtjflvcDZwC09hcDTw7Xj9hmtrokScvKKGH9b8CmJC9of/d8LvAQ8Angja3PVuC2tryzrdPa76yqavWL293iZwHrgX8B7gbWt7vLT2ZwE9rOEcYrSdJEWnH0LjOrqruS3Ap8GjgE3AtcD/wdcHOSP2i1G9omNwB/mWQaOMggfKmqB5PcwiDoDwFXVNV3AJK8HdjN4E7zHVX14ELHK0nSpFpwWANU1XZg+xHlRxncyX1k3/8EfmmW/VwNXD1DfRewa5QxSpI06XyCmSRJnTOsJUnqnGEtSVLnDGtJkjpnWEuS1DnDWpKkzhnWkiR1zrCWJKlzhrUkSZ0zrCVJ6pxhLUlS5wxrSZI6Z1hLktQ5w1qSpM4Z1pIkdc6wliSpc4a1JEmdM6wlSeqcYS1JUucMa0mSOmdYS5LUOcNakqTOGdaSJHXOsJYkqXOGtSRJnTOsJUnqnGEtSVLnDGtJkjpnWEuS1DnDWpKkzhnWkiR1zrCWJKlzhrUkSZ0zrCVJ6pxhLUlS5wxrSZI6Z1hLktQ5w1qSpM4Z1pIkdc6wliSpc4a1JEmdM6wlSeqcYS1JUucMa0mSOmdYS5LUOcNakqTOjRTWSU5JcmuSzyZ5OMmPJzk1yZ4kj7SvK1vfJLk2yXSSzyQ5e2g/W1v/R5JsHaq/Osn9bZtrk2SU8UqSNIlGPbP+U+Dvq+rlwI8BDwNXAndU1XrgjrYOcAGwvr22AdcBJDkV2A68BjgH2H444Fuftw5tt3nE8UqSNHEWHNZJXgy8DrgBoKq+XVVfA7YAN7ZuNwIXteUtwE01sBc4JcnpwPnAnqo6WFVPAXuAza3tRVW1t6oKuGloX5IkLRujnFmfBRwA/iLJvUnen+SFwGlV9Xjr8xXgtLa8BnhsaPt9rTZXfd8M9WdJsi3JVJKpAwcOjDAlSZL6M0pYrwDOBq6rqlcB3+T/LnkD0M6Ia4T3mJequr6qNlbVxtWrV5/ot5MkaVGNEtb7gH1VdVdbv5VBeH+1XcKmfX2ite8Hzhjafm2rzVVfO0NdkqRlZcFhXVVfAR5L8sOtdC7wELATOHxH91bgtra8E7i03RW+CXi6XS7fDZyXZGW7sew8YHdreybJpnYX+KVD+5IkadlYMeL2vwp8MMnJwKPAZQx+AbglyeXAl4E3tb67gAuBaeBbrS9VdTDJu4G7W7+rqupgW34b8AHg+cDt7SVJ0rIyUlhX1X3Axhmazp2hbwFXzLKfHcCOGepTwCtHGaMkSZPOJ5hJktQ5w1qSpM4Z1pIkdc6wliSpc4a1JEmdM6wlSeqcYS1JUucMa0mSOmdYS5LUOcNakqTOGdaSJHXOsJYkqXOGtSRJnTOsJUnqnGEtSVLnDGtJkjpnWEuS1DnDWpKkzhnWkiR1zrCWJKlzhrUkSZ0zrCVJ6pxhLUlS5wxrSZI6Z1hLktQ5w1qSpM4Z1pIkdc6wliSpc4a1JEmdM6wlSeqcYS1JUucMa0mSOmdYS5LUOcNakqTOGdaSJHXOsJYkqXOGtSRJnTOsJUnqnGEtSVLnDGtJkjpnWEuS1DnDWpKkzhnWkiR1zrCWJKlzhrUkSZ0bOayTnJTk3iQfa+tnJbkryXSSv0lycqs/t61Pt/Z1Q/t4Z6t/Lsn5Q/XNrTad5MpRxypJ0iQ6HmfW7wAeHlr/Q+CaqnoZ8BRweatfDjzV6te0fiTZAFwMvALYDLyv/QJwEvBe4AJgA3BJ6ytJ0rIyUlgnWQv8LPD+th7gDcCtrcuNwEVteUtbp7Wf2/pvAW6uqv+qqi8C08A57TVdVY9W1beBm1tfSZKWlVHPrP8E+G3gu239JcDXqupQW98HrGnLa4DHAFr7063//9aP2Ga2uiRJy8qCwzrJzwFPVNU9x3E8Cx3LtiRTSaYOHDgw7uFIknRcjXJm/VrgF5J8icEl6jcAfwqckmRF67MW2N+W9wNnALT2FwNPDteP2Ga2+rNU1fVVtbGqNq5evXqEKUmS1J8Fh3VVvbOq1lbVOgY3iN1ZVW8GPgG8sXXbCtzWlne2dVr7nVVVrX5xu1v8LGA98C/A3cD6dnf5ye09di50vJIkTaoVR+9yzH4HuDnJHwD3Aje0+g3AXyaZBg4yCF+q6sEktwAPAYeAK6rqOwBJ3g7sBk4CdlTVgydgvJIkde24hHVVfRL4ZFt+lMGd3Ef2+U/gl2bZ/mrg6hnqu4Bdx2OMkiRNKp9gJklS5wxrSZI6Z1hLktQ5w1qSpM4Z1pIkdc6wliSpc4a1JEmdM6wlSeqcYS1JUucMa0mSOmdYS5LUOcNakqTOGdaSJHXOsJYkqXOGtSRJnTOsJUnqnGEtSVLnDGtJkjpnWEuS1DnDWpKkzhnWkiR1zrCWJKlzhrUkSZ0zrCVJ6pxhLUlS5wxrSZI6Z1hLktQ5w1qSpM4Z1pIkdc6wliSpc4a1JEmdM6wlSeqcYS1JUucMa0mSOmdYS5LUOcNakqTOGdaSJHXOsJYkqXOGtSRJnTOsJUnqnGEtSVLnDGtJkjpnWEuS1DnDWpKkzhnWkiR1zrCWJKlzCw7rJGck+USSh5I8mOQdrX5qkj1JHmlfV7Z6klybZDrJZ5KcPbSvra3/I0m2DtVfneT+ts21STLKZCVJmkSjnFkfAn6zqjYAm4ArkmwArgTuqKr1wB1tHeACYH17bQOug0G4A9uB1wDnANsPB3zr89ah7TaPMF5JkibSgsO6qh6vqk+35a8DDwNrgC3Aja3bjcBFbXkLcFMN7AVOSXI6cD6wp6oOVtVTwB5gc2t7UVXtraoCbhralyRJy8Zx+TvrJOuAVwF3AadV1eOt6SvAaW15DfDY0Gb7Wm2u+r4Z6pIkLSsjh3WS7wU+DPx6VT0z3NbOiGvU95jHGLYlmUoydeDAgRP9dpIkLaqRwjrJcxgE9Qer6iOt/NV2CZv29YlW3w+cMbT52labq752hvqzVNX1VbWxqjauXr16lClJktSdUe4GD3AD8HBV/fFQ007g8B3dW4HbhuqXtrvCNwFPt8vlu4HzkqxsN5adB+xubc8k2dTe69KhfUmStGysGGHb1wJvAe5Pcl+r/S7wHuCWJJcDXwbe1Np2ARcC08C3gMsAqupgkncDd7d+V1XVwbb8NuADwPOB29tLkqRlZcFhXVX/AMz2757PnaF/AVfMsq8dwI4Z6lPAKxc6RkmSlgKfYCZJUucMa0mSOmdYS5LUOcNakqTOGdaSJHXOsJYkqXOGtSRJnTOsJUnqnGEtSVLnDGtJkjpnWEuS1DnDWpKkzhnWkiR1zrCWJKlzhrUkSZ0zrCVJ6pxhLUlS5wxrSZI6Z1hLktQ5w1qSpM4Z1pIkdc6wliSpc4a1JEmdM6wlSeqcYS1JUucMa0mSOmdYS5LUOcNakqTOGdaSJHXOsJYkqXOGtSRJnTOsJUnqnGEtSVLnDGtJkjpnWEuS1DnDWpKkzhnWkiR1zrCWJKlzhrUkSZ0zrCVJ6pxhLUlS5wxrSZI6Z1hLktQ5w1qSpM4Z1pIkdc6wliSpc92HdZLNST6XZDrJleMejyRJi63rsE5yEvBe4AJgA3BJkg3jHZUkSYur67AGzgGmq+rRqvo2cDOwZcxjkiRpUfUe1muAx4bW97WaJEnLxopxD+B4SLIN2NZWv5Hkc+Mcz3G2Cvj3cQ/iBFmqcxv7vH7/LSds12Of2wmyVOcFS3duY5/XCTjOXjpbQ+9hvR84Y2h9bav9P1V1PXD9Yg1qMSWZqqqN4x7HibBU57ZU5wVLd25LdV6wdOe2VOc1m94vg98NrE9yVpKTgYuBnWMekyRJi6rrM+uqOpTk7cBu4CRgR1U9OOZhSZK0qLoOa4Cq2gXsGvc4xmhJXt5vlurcluq8YOnObanOC5bu3JbqvGaUqhr3GCRJ0hx6/ztrSZKWPcN6jI72KNUk1yS5r70+n+RrQ23fGWrr6qa7JDuSPJHkgVnak+TaNu/PJDl7qG1rkkfaa+vijfro5jGvN7f53J/kn5L82FDbl1r9viRTizfq+ZnH3F6f5Omh77l3DbV1+0jgeczrt4bm9EA7rk5tbb1/Zmck+USSh5I8mOQdM/SZuGNtnvOa2GNtwarK1xheDG6Y+wLwQ8DJwL8CG+bo/6sMbrA7vP6Ncc9hjrG+DjgbeGCW9guB24EAm4C7Wv1U4NH2dWVbXjnu+RzDvH7i8HgZPCL3rqG2LwGrxj2HEeb2euBjM9SP6fu4t3kd0ffngTsn6DM7HTi7LX8f8Pkj/+wn8Vib57wm9lhb6Msz6/E51kepXgJ8aFFGNqKq+hRwcI4uW4CbamAvcEqS04HzgT1VdbCqngL2AJtP/Ijn52jzqqp/auMG2MvguQATYR6f2Wy6fiTwMc5rYo4xgKp6vKo+3Za/DjzMs5/wOHHH2nzmNcnH2kIZ1uMz70epJnkpcBZw51D5eUmmkuxNctGJG+YJMdvcl9LjZS9ncEZzWAEfT3JPe+LeJPrxJP+a5PYkr2i1JfGZJXkBg7D68FB5Yj6zJOuAVwF3HdE00cfaHPMathSPtWfp/p9uCRg8DObWqvrOUO2lVbU/yQ8Bdya5v6q+MKbxaUiSn2bwA+Qnh8o/2T6v7wf2JPlsO+ubFJ9m8D33jSQXAn8LrB/zmI6nnwf+saqGz8In4jNL8r0Mfsn49ap6ZtzjOV7mM68leqzNyDPr8ZnXo1Sbizni8lxV7W9fHwU+yeC3z0kx29yP5c+kS0l+FHg/sKWqnjxcH/q8ngA+yuDy8cSoqmeq6htteRfwnCSrWAKfWTPXMdbtZ5bkOQwC7YNV9ZEZukzksTaPeS3ZY202hvX4zOtRqklezuAGkH8eqq1M8ty2vAp4LfDQooz6+NgJXNruVN0EPF1VjzN4Ut15bX4rgfNabSIkORP4CPCWqvr8UP2FSb7v8DKDec14d3KvkvxAkrTlcxj87HiSJfBI4CQvBn4KuG2o1v1n1j6PG4CHq+qPZ+k2ccfafOa1lI+12XgZfExqlkepJrkKmKqqwz/wLgZurnabY/MjwJ8n+S6DH5rvqapuwjrJhxjcPbwqyT5gO/AcgKr6MwZPpLsQmAa+BVzW2g4meTeDAAC46ojLkmM1j3m9C3gJ8L6Wa4dq8B8NnAZ8tNVWAH9dVX+/6BOYwzzm9kbgV5IcAv4DuLh9T3b9SOB5zAvgF4GPV9U3hzbt/jNj8Ev6W4D7k9zXar8LnAkTfazNZ14Te6wtlE8wkySpc14GlySpc4a1JEmdM6wlSeqcYS1JUucMa0mSOmdYS5LUOcNakqTOGdaSJHXufwDzc/QmpFB42wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sentence = df['review'].tolist()\n",
        "label1 = df['sentiment'].tolist()\n",
        "\n",
        "c = Counter(label1)\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "Intent = []\n",
        "Occurance = []\n",
        "for i in c.items():\n",
        "  Intent.append(i[0])\n",
        "  Occurance.append(i[1])\n",
        "ax.bar(Intent,Occurance,color=(0.2, 0.4, 0.6, 0.6))  \n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MkV9gziw8-u"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MOfbnVZN-yh"
      },
      "outputs": [],
      "source": [
        "dic={1:0,2:1}\n",
        "ans={0:1,1:2}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAnL8ekpu9Cj",
        "outputId": "57de779d-fde7-4803-a333-2b545245ba11"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/200000 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n",
            "100%|██████████| 200000/200000 [00:48<00:00, 4118.21it/s]\n"
          ]
        }
      ],
      "source": [
        "labels=data['sentiment']\n",
        "sentence=data['review']\n",
        "\n",
        "for i in tqdm(range(len(labels))):\n",
        "  labels[i]=dic[labels[i]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kzB-cbMOyVJ",
        "outputId": "aef9f423-03d0-49a3-dca0-525b3ed9526d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200000\n",
            "199869\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(label1)):\n",
        " label1[i]=dic[label1[i]]\n",
        "\n",
        "data={'sentence':sentence,'label1':labels}\n",
        "df=pd.DataFrame(data)\n",
        "print(len(df))\n",
        "df=df.drop_duplicates()\n",
        "print(len(df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_uwuxrGwSkj"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(sentence, label1, test_size = 0.20, random_state = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qs928X_GwSjJ"
      },
      "outputs": [],
      "source": [
        "sentences = X_train\n",
        "labels = y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IkUNRhFIwciE"
      },
      "outputs": [],
      "source": [
        "label_1_num_classes = 2\n",
        "\n",
        "label1 = torch.LongTensor(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDawdeDgxy-O"
      },
      "source": [
        "# Loading RoBERTa Model and Creating Data Frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234,
          "referenced_widgets": [
            "3bc6747f96db4cdb940695f4181e85b4",
            "7c396ed308d2464f943c67986da7adab",
            "aab223fc56bb45a39d945ae7cc9f245d",
            "87ed97427e5d4b4a872c009fdc9b82b9",
            "45694a35b5cd458e9e907d6b724db052",
            "b8fb37721eae4af49bd36e0f9890d24d",
            "6515ffbe08894525bdc38fa035e59ce8",
            "8dad4f6b39374037bdf40573fb056900",
            "8ee3e2f66370415e9946452e6e16aa25",
            "3391af5bfb1943d6b830389bed4a0315",
            "3655fa1c25714391b15483ee803e2db2",
            "dc1a268fadff4da681885addd39a5d27",
            "606b2f6f828e4e14a62dd23f4a253dda",
            "07945106a62d431abaef733532b21cfb",
            "70b581026b4d4bf1a5f67d0fa4d71728",
            "bcd0457a22ec4211a3db41e141e053f6",
            "41434b4e593344dea17555c76c50d884",
            "3c03d17b258b4c53a3fbc4b8642622c7",
            "9e89a5e0c424458ba2bab68ecaf72f3d",
            "65b1232c0f5b47d2a8f907342529b9ec",
            "d5efa6fc4f9b4c07aa52390dfd3e62cc",
            "f2ee44c67e1f48fdb7bd6cacffea65dc",
            "0fa733348c3a4df8873e28c5822357b5",
            "21006283c6d64ec8abff78aeccde9f49",
            "3c343821bab447c2b9a4fc4d6435ec3e",
            "eaacb8a8f1ea4ec180f012bfb70176e3",
            "20f8a8490f56441d9764132cf53ddfcb",
            "3d85213a949a4cda8e3af356a6765943",
            "36a8f86fbabc47d198c675f23e3b9d05",
            "4ee3fb012abc4163ad8a1823e44fcf95",
            "45ce266fef514f8a9e92c5dd20fbb980",
            "5e1ed889061f480abdbe780dc21e2e92",
            "52860b9c009c41cd93aaf2c1cdb1fe2a",
            "a8d9f3dbfc5848f58ecb03490f5bf2db",
            "61e9d4e120bb41e3bef85b9e1017bdf6",
            "a2ed3110a1b9455d9cbb29413380278c",
            "02b21f78bab24a5fbd0fa490d6b0d883",
            "b7eef61f25f84c9c9dbf73b5bbbadfac",
            "5e27135b02e04bbdbb91806023e62b8d",
            "95b5af8c1f284f608237a4d482bbe4d0",
            "74ad18e54a5a4fb4a8a1454fd1749570",
            "22baf62f26bd44f3b052ba12efb53bb7",
            "76d7ac888798422fb1d9c19fe34cbf25",
            "d2515affaad64fd090c18dddec605c61"
          ]
        },
        "id": "iDsAxHLAxwUX",
        "outputId": "3c42ee6a-3221-4b70-83ea-388373326e11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading RoBERTa tokenizer...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3bc6747f96db4cdb940695f4181e85b4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dc1a268fadff4da681885addd39a5d27",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0fa733348c3a4df8873e28c5822357b5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a8d9f3dbfc5848f58ecb03490f5bf2db",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Original:  This is a self-published book, and if you want to know why--read a few paragraphs! Those 5 star reviews must have been written by Ms. Haddon's family and friends--or perhaps, by herself! I can't imagine anyone reading the whole thing--I spent an evening with the book and a friend and we were in hysterics reading bits and pieces of it to one another. It is most definitely bad enough to be entered into some kind of a \"worst book\" contest. I can't believe Amazon even sells this kind of thing. Maybe I can offer them my 8th grade term paper on \"To Kill a Mockingbird\"--a book I am quite sure Ms. Haddon never heard of. Anyway, unless you are in a mood to send a book to someone as a joke---stay far, far away from this one!\n",
            "Tokenized:  ['This', 'Ġis', 'Ġa', 'Ġself', '-', 'published', 'Ġbook', ',', 'Ġand', 'Ġif', 'Ġyou', 'Ġwant', 'Ġto', 'Ġknow', 'Ġwhy', '--', 'read', 'Ġa', 'Ġfew', 'Ġparagraphs', '!', 'ĠThose', 'Ġ5', 'Ġstar', 'Ġreviews', 'Ġmust', 'Ġhave', 'Ġbeen', 'Ġwritten', 'Ġby', 'ĠMs', '.', 'ĠH', 'addon', \"'s\", 'Ġfamily', 'Ġand', 'Ġfriends', '--', 'or', 'Ġperhaps', ',', 'Ġby', 'Ġherself', '!', 'ĠI', 'Ġcan', \"'t\", 'Ġimagine', 'Ġanyone', 'Ġreading', 'Ġthe', 'Ġwhole', 'Ġthing', '--', 'I', 'Ġspent', 'Ġan', 'Ġevening', 'Ġwith', 'Ġthe', 'Ġbook', 'Ġand', 'Ġa', 'Ġfriend', 'Ġand', 'Ġwe', 'Ġwere', 'Ġin', 'Ġhyster', 'ics', 'Ġreading', 'Ġbits', 'Ġand', 'Ġpieces', 'Ġof', 'Ġit', 'Ġto', 'Ġone', 'Ġanother', '.', 'ĠIt', 'Ġis', 'Ġmost', 'Ġdefinitely', 'Ġbad', 'Ġenough', 'Ġto', 'Ġbe', 'Ġentered', 'Ġinto', 'Ġsome', 'Ġkind', 'Ġof', 'Ġa', 'Ġ\"', 'worst', 'Ġbook', '\"', 'Ġcontest', '.', 'ĠI', 'Ġcan', \"'t\", 'Ġbelieve', 'ĠAmazon', 'Ġeven', 'Ġsells', 'Ġthis', 'Ġkind', 'Ġof', 'Ġthing', '.', 'ĠMaybe', 'ĠI', 'Ġcan', 'Ġoffer', 'Ġthem', 'Ġmy', 'Ġ8', 'th', 'Ġgrade', 'Ġterm', 'Ġpaper', 'Ġon', 'Ġ\"', 'To', 'ĠKill', 'Ġa', 'ĠM', 'ocking', 'bird', '\"', '--', 'a', 'Ġbook', 'ĠI', 'Ġam', 'Ġquite', 'Ġsure', 'ĠMs', '.', 'ĠH', 'addon', 'Ġnever', 'Ġheard', 'Ġof', '.', 'ĠAnyway', ',', 'Ġunless', 'Ġyou', 'Ġare', 'Ġin', 'Ġa', 'Ġmood', 'Ġto', 'Ġsend', 'Ġa', 'Ġbook', 'Ġto', 'Ġsomeone', 'Ġas', 'Ġa', 'Ġjoke', '---', 'stay', 'Ġfar', ',', 'Ġfar', 'Ġaway', 'Ġfrom', 'Ġthis', 'Ġone', '!']\n",
            "Token IDs:  [713, 16, 10, 1403, 12, 34167, 1040, 6, 8, 114, 47, 236, 7, 216, 596, 5579, 12745, 10, 367, 36153, 328, 2246, 195, 999, 6173, 531, 33, 57, 1982, 30, 2135, 4, 289, 42246, 18, 284, 8, 964, 5579, 368, 2532, 6, 30, 2864, 328, 38, 64, 75, 4744, 1268, 2600, 5, 1086, 631, 5579, 100, 1240, 41, 1559, 19, 5, 1040, 8, 10, 1441, 8, 52, 58, 11, 42462, 2857, 2600, 15239, 8, 3745, 9, 24, 7, 65, 277, 4, 85, 16, 144, 2299, 1099, 615, 7, 28, 2867, 88, 103, 761, 9, 10, 22, 24390, 1040, 113, 3096, 4, 38, 64, 75, 679, 1645, 190, 7683, 42, 761, 9, 631, 4, 5359, 38, 64, 904, 106, 127, 290, 212, 4978, 1385, 2225, 15, 22, 3972, 14212, 10, 256, 12088, 15886, 113, 5579, 102, 1040, 38, 524, 1341, 686, 2135, 4, 289, 42246, 393, 1317, 9, 4, 24820, 6, 3867, 47, 32, 11, 10, 6711, 7, 2142, 10, 1040, 7, 951, 25, 10, 8018, 24965, 20952, 444, 6, 444, 409, 31, 42, 65, 328]\n"
          ]
        }
      ],
      "source": [
        "print('Loading RoBERTa tokenizer...')\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base', do_lower_case=True)\n",
        "\n",
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyJAOEQix40-",
        "outputId": "45efdb99-8d60-479f-e04c-89caea31bfd8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/160000 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2310: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100%|██████████| 160000/160000 [01:06<00:00, 2409.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original:  This is a self-published book, and if you want to know why--read a few paragraphs! Those 5 star reviews must have been written by Ms. Haddon's family and friends--or perhaps, by herself! I can't imagine anyone reading the whole thing--I spent an evening with the book and a friend and we were in hysterics reading bits and pieces of it to one another. It is most definitely bad enough to be entered into some kind of a \"worst book\" contest. I can't believe Amazon even sells this kind of thing. Maybe I can offer them my 8th grade term paper on \"To Kill a Mockingbird\"--a book I am quite sure Ms. Haddon never heard of. Anyway, unless you are in a mood to send a book to someone as a joke---stay far, far away from this one!\n",
            "Token IDs: tensor([    0,   100,   269,  3776,    42,  1040,     4, 15852,   393,  1166,\n",
            "           42,  2730,   137,     6,    38,   399,    75,   216,    99,     7,\n",
            "         1057,     8,    38,    21, 35554,  3911,     4,    20,  1049,  2048,\n",
            "           21,   182, 26669,   868,     8,   156,   162,   236,     7,  1166,\n",
            "           55, 10125,  5227,  2799,     4,  6802,     6,   627,    97,  2799,\n",
            "           11,     5,  2094, 24600, 20846,    58,    45,    25,   157,  1982,\n",
            "            8, 46405,    33,     5,  2048,  2179,  6285,    14,    42,  1040,\n",
            "           56,     4,     2,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1])\n"
          ]
        }
      ],
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for sent in tqdm(sentences):\n",
        "    encoded_dict = tokenizer.encode_plus(sent,add_special_tokens = True,max_length = 512,pad_to_max_length = True,\n",
        "                        return_attention_mask = True, return_tensors = 'pt',)\n",
        "    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "all_labels = torch.stack([label1], dim=1)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XqaL5G_x4rW",
        "outputId": "0a1ffb2b-2490-4811-d835-7ded680bfb67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "144,000 training samples\n",
            "16,000 validation samples\n"
          ]
        }
      ],
      "source": [
        "dataset = TensorDataset(input_ids, attention_masks, all_labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wrGxMf6yFHd"
      },
      "source": [
        "# Training on label 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1f9ec2448f734b35a14d5b67159636ed",
            "d2951498bd774b058e55f744c831a97f",
            "580540de040c49369350c981c638097c",
            "856592d5d8634ba8a1988673bc7600c6",
            "e2b150cd67444738bb14e61becb8a4f0",
            "130e497ad2c9449986ac66101d459e11",
            "593adab5fe234b778d00d174096b3576",
            "0b08b69721f143efb0b210a0c6ca37e4",
            "a921172a574c4aebb5e0ca4426f41fd7",
            "7115292ee45f4d65807c7d00ebb73d5a",
            "1cc9866a8acd44c9ba2ebb01499d1163"
          ]
        },
        "id": "Kx29Kr9byEmV",
        "outputId": "ba8a659e-c615-4f0f-91bb-b7fd634053d9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1f9ec2448f734b35a14d5b67159636ed",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/501M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'roberta.pooler.dense.bias', 'lm_head.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "RobertaForSequenceClassification(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): RobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_size = 32\n",
        "train_dataloader = DataLoader( train_dataset, shuffle=True, batch_size = batch_size)\n",
        "validation_dataloader = DataLoader( val_dataset, shuffle=False, batch_size = batch_size )\n",
        "\n",
        "\n",
        "model = RobertaForSequenceClassification.from_pretrained( \n",
        "    \"roberta-base\", num_labels = 2, output_attentions = False, output_hidden_states = False)\n",
        "\n",
        "model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umd9G6H8yLmd",
        "outputId": "a7a32856-f98a-46bc-adf5-27a959d0efa6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "optimizer = AdamW(model.parameters(), lr = 2e-5, eps = 1e-8 )\n",
        "\n",
        "epochs = 4\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = total_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yewC5MrPyNwE"
      },
      "outputs": [],
      "source": [
        "def flat_accuracy(preds1,labels):\n",
        "    pred_flat1 = np.argmax(preds1, axis=1).flatten()\n",
        "    labels = labels.flatten() \n",
        "    labels_flat1=np.asarray(labels)\n",
        "    acc1= np.sum(pred_flat1 == labels_flat1) / len(labels_flat1)\n",
        "    #return (acc1+acc2)/2\n",
        "    return acc1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLr9N5nhyPci"
      },
      "outputs": [],
      "source": [
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "388lbJ0xyPTQ",
        "outputId": "f251a6a8-edd7-4e3a-bea8-232fc8b303e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  4,500.    Elapsed: 0:00:29.\n",
            "  Batch    80  of  4,500.    Elapsed: 0:00:57.\n",
            "  Batch   120  of  4,500.    Elapsed: 0:01:25.\n",
            "  Batch   160  of  4,500.    Elapsed: 0:01:53.\n",
            "  Batch   200  of  4,500.    Elapsed: 0:02:20.\n",
            "  Batch   240  of  4,500.    Elapsed: 0:02:48.\n",
            "  Batch   280  of  4,500.    Elapsed: 0:03:16.\n",
            "  Batch   320  of  4,500.    Elapsed: 0:03:44.\n",
            "  Batch   360  of  4,500.    Elapsed: 0:04:12.\n",
            "  Batch   400  of  4,500.    Elapsed: 0:04:40.\n",
            "  Batch   440  of  4,500.    Elapsed: 0:05:08.\n",
            "  Batch   480  of  4,500.    Elapsed: 0:05:35.\n",
            "  Batch   520  of  4,500.    Elapsed: 0:06:03.\n",
            "  Batch   560  of  4,500.    Elapsed: 0:06:31.\n",
            "  Batch   600  of  4,500.    Elapsed: 0:06:59.\n",
            "  Batch   640  of  4,500.    Elapsed: 0:07:27.\n",
            "  Batch   680  of  4,500.    Elapsed: 0:07:55.\n",
            "  Batch   720  of  4,500.    Elapsed: 0:08:23.\n",
            "  Batch   760  of  4,500.    Elapsed: 0:08:51.\n",
            "  Batch   800  of  4,500.    Elapsed: 0:09:18.\n",
            "  Batch   840  of  4,500.    Elapsed: 0:09:46.\n",
            "  Batch   880  of  4,500.    Elapsed: 0:10:14.\n",
            "  Batch   920  of  4,500.    Elapsed: 0:10:42.\n",
            "  Batch   960  of  4,500.    Elapsed: 0:11:10.\n",
            "  Batch 1,000  of  4,500.    Elapsed: 0:11:38.\n",
            "  Batch 1,040  of  4,500.    Elapsed: 0:12:06.\n",
            "  Batch 1,080  of  4,500.    Elapsed: 0:12:33.\n",
            "  Batch 1,120  of  4,500.    Elapsed: 0:13:01.\n",
            "  Batch 1,160  of  4,500.    Elapsed: 0:13:29.\n",
            "  Batch 1,200  of  4,500.    Elapsed: 0:13:57.\n",
            "  Batch 1,240  of  4,500.    Elapsed: 0:14:25.\n",
            "  Batch 1,280  of  4,500.    Elapsed: 0:14:53.\n",
            "  Batch 1,320  of  4,500.    Elapsed: 0:15:21.\n",
            "  Batch 1,360  of  4,500.    Elapsed: 0:15:48.\n",
            "  Batch 1,400  of  4,500.    Elapsed: 0:16:16.\n",
            "  Batch 1,440  of  4,500.    Elapsed: 0:16:44.\n",
            "  Batch 1,480  of  4,500.    Elapsed: 0:17:12.\n",
            "  Batch 1,520  of  4,500.    Elapsed: 0:17:40.\n",
            "  Batch 1,560  of  4,500.    Elapsed: 0:18:08.\n",
            "  Batch 1,600  of  4,500.    Elapsed: 0:18:36.\n",
            "  Batch 1,640  of  4,500.    Elapsed: 0:19:04.\n",
            "  Batch 1,680  of  4,500.    Elapsed: 0:19:31.\n",
            "  Batch 1,720  of  4,500.    Elapsed: 0:19:59.\n",
            "  Batch 1,760  of  4,500.    Elapsed: 0:20:27.\n",
            "  Batch 1,800  of  4,500.    Elapsed: 0:20:55.\n",
            "  Batch 1,840  of  4,500.    Elapsed: 0:21:23.\n",
            "  Batch 1,880  of  4,500.    Elapsed: 0:21:51.\n",
            "  Batch 1,920  of  4,500.    Elapsed: 0:22:19.\n",
            "  Batch 1,960  of  4,500.    Elapsed: 0:22:47.\n",
            "  Batch 2,000  of  4,500.    Elapsed: 0:23:14.\n",
            "  Batch 2,040  of  4,500.    Elapsed: 0:23:42.\n",
            "  Batch 2,080  of  4,500.    Elapsed: 0:24:10.\n",
            "  Batch 2,120  of  4,500.    Elapsed: 0:24:38.\n",
            "  Batch 2,160  of  4,500.    Elapsed: 0:25:06.\n",
            "  Batch 2,200  of  4,500.    Elapsed: 0:25:34.\n",
            "  Batch 2,240  of  4,500.    Elapsed: 0:26:02.\n",
            "  Batch 2,280  of  4,500.    Elapsed: 0:26:30.\n",
            "  Batch 2,320  of  4,500.    Elapsed: 0:26:57.\n",
            "  Batch 2,360  of  4,500.    Elapsed: 0:27:25.\n",
            "  Batch 2,400  of  4,500.    Elapsed: 0:27:53.\n",
            "  Batch 2,440  of  4,500.    Elapsed: 0:28:21.\n",
            "  Batch 2,480  of  4,500.    Elapsed: 0:28:49.\n",
            "  Batch 2,520  of  4,500.    Elapsed: 0:29:17.\n",
            "  Batch 2,560  of  4,500.    Elapsed: 0:29:45.\n",
            "  Batch 2,600  of  4,500.    Elapsed: 0:30:12.\n",
            "  Batch 2,640  of  4,500.    Elapsed: 0:30:40.\n",
            "  Batch 2,680  of  4,500.    Elapsed: 0:31:08.\n",
            "  Batch 2,720  of  4,500.    Elapsed: 0:31:36.\n",
            "  Batch 2,760  of  4,500.    Elapsed: 0:32:04.\n",
            "  Batch 2,800  of  4,500.    Elapsed: 0:32:32.\n",
            "  Batch 2,840  of  4,500.    Elapsed: 0:32:59.\n",
            "  Batch 2,880  of  4,500.    Elapsed: 0:33:27.\n",
            "  Batch 2,920  of  4,500.    Elapsed: 0:33:55.\n",
            "  Batch 2,960  of  4,500.    Elapsed: 0:34:23.\n",
            "  Batch 3,000  of  4,500.    Elapsed: 0:34:51.\n",
            "  Batch 3,040  of  4,500.    Elapsed: 0:35:19.\n",
            "  Batch 3,080  of  4,500.    Elapsed: 0:35:47.\n",
            "  Batch 3,120  of  4,500.    Elapsed: 0:36:14.\n",
            "  Batch 3,160  of  4,500.    Elapsed: 0:36:42.\n",
            "  Batch 3,200  of  4,500.    Elapsed: 0:37:10.\n",
            "  Batch 3,240  of  4,500.    Elapsed: 0:37:38.\n",
            "  Batch 3,280  of  4,500.    Elapsed: 0:38:06.\n",
            "  Batch 3,320  of  4,500.    Elapsed: 0:38:34.\n",
            "  Batch 3,360  of  4,500.    Elapsed: 0:39:01.\n",
            "  Batch 3,400  of  4,500.    Elapsed: 0:39:29.\n",
            "  Batch 3,440  of  4,500.    Elapsed: 0:39:57.\n",
            "  Batch 3,480  of  4,500.    Elapsed: 0:40:25.\n",
            "  Batch 3,520  of  4,500.    Elapsed: 0:40:53.\n",
            "  Batch 3,560  of  4,500.    Elapsed: 0:41:21.\n",
            "  Batch 3,600  of  4,500.    Elapsed: 0:41:49.\n",
            "  Batch 3,640  of  4,500.    Elapsed: 0:42:16.\n",
            "  Batch 3,680  of  4,500.    Elapsed: 0:42:44.\n",
            "  Batch 3,720  of  4,500.    Elapsed: 0:43:12.\n",
            "  Batch 3,760  of  4,500.    Elapsed: 0:43:40.\n",
            "  Batch 3,800  of  4,500.    Elapsed: 0:44:08.\n",
            "  Batch 3,840  of  4,500.    Elapsed: 0:44:36.\n",
            "  Batch 3,880  of  4,500.    Elapsed: 0:45:03.\n",
            "  Batch 3,920  of  4,500.    Elapsed: 0:45:31.\n",
            "  Batch 3,960  of  4,500.    Elapsed: 0:45:59.\n",
            "  Batch 4,000  of  4,500.    Elapsed: 0:46:27.\n",
            "  Batch 4,040  of  4,500.    Elapsed: 0:46:55.\n",
            "  Batch 4,080  of  4,500.    Elapsed: 0:47:23.\n",
            "  Batch 4,120  of  4,500.    Elapsed: 0:47:51.\n",
            "  Batch 4,160  of  4,500.    Elapsed: 0:48:18.\n",
            "  Batch 4,200  of  4,500.    Elapsed: 0:48:46.\n",
            "  Batch 4,240  of  4,500.    Elapsed: 0:49:14.\n",
            "  Batch 4,280  of  4,500.    Elapsed: 0:49:42.\n",
            "  Batch 4,320  of  4,500.    Elapsed: 0:50:10.\n",
            "  Batch 4,360  of  4,500.    Elapsed: 0:50:38.\n",
            "  Batch 4,400  of  4,500.    Elapsed: 0:51:05.\n",
            "  Batch 4,440  of  4,500.    Elapsed: 0:51:33.\n",
            "  Batch 4,480  of  4,500.    Elapsed: 0:52:01.\n",
            "\n",
            "  Average training loss: 0.16\n",
            "  Training epcoh took: 0:52:15\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy1: 0.96\n",
            "  Validation Loss: 0.13\n",
            "  Validation took: 0:01:48\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  4,500.    Elapsed: 0:00:28.\n",
            "  Batch    80  of  4,500.    Elapsed: 0:00:56.\n",
            "  Batch   120  of  4,500.    Elapsed: 0:01:24.\n",
            "  Batch   160  of  4,500.    Elapsed: 0:01:51.\n",
            "  Batch   200  of  4,500.    Elapsed: 0:02:19.\n",
            "  Batch   240  of  4,500.    Elapsed: 0:02:47.\n",
            "  Batch   280  of  4,500.    Elapsed: 0:03:15.\n",
            "  Batch   320  of  4,500.    Elapsed: 0:03:43.\n",
            "  Batch   360  of  4,500.    Elapsed: 0:04:10.\n",
            "  Batch   400  of  4,500.    Elapsed: 0:04:38.\n",
            "  Batch   440  of  4,500.    Elapsed: 0:05:06.\n",
            "  Batch   480  of  4,500.    Elapsed: 0:05:34.\n",
            "  Batch   520  of  4,500.    Elapsed: 0:06:02.\n",
            "  Batch   560  of  4,500.    Elapsed: 0:06:29.\n",
            "  Batch   600  of  4,500.    Elapsed: 0:06:57.\n",
            "  Batch   640  of  4,500.    Elapsed: 0:07:25.\n",
            "  Batch   680  of  4,500.    Elapsed: 0:07:53.\n",
            "  Batch   720  of  4,500.    Elapsed: 0:08:21.\n",
            "  Batch   760  of  4,500.    Elapsed: 0:08:49.\n",
            "  Batch   800  of  4,500.    Elapsed: 0:09:16.\n",
            "  Batch   840  of  4,500.    Elapsed: 0:09:44.\n",
            "  Batch   880  of  4,500.    Elapsed: 0:10:12.\n",
            "  Batch   920  of  4,500.    Elapsed: 0:10:40.\n",
            "  Batch   960  of  4,500.    Elapsed: 0:11:08.\n",
            "  Batch 1,000  of  4,500.    Elapsed: 0:11:35.\n",
            "  Batch 1,040  of  4,500.    Elapsed: 0:12:03.\n",
            "  Batch 1,080  of  4,500.    Elapsed: 0:12:31.\n",
            "  Batch 1,120  of  4,500.    Elapsed: 0:12:59.\n",
            "  Batch 1,160  of  4,500.    Elapsed: 0:13:27.\n",
            "  Batch 1,200  of  4,500.    Elapsed: 0:13:55.\n",
            "  Batch 1,240  of  4,500.    Elapsed: 0:14:22.\n",
            "  Batch 1,280  of  4,500.    Elapsed: 0:14:50.\n",
            "  Batch 1,320  of  4,500.    Elapsed: 0:15:18.\n",
            "  Batch 1,360  of  4,500.    Elapsed: 0:15:46.\n",
            "  Batch 1,400  of  4,500.    Elapsed: 0:16:14.\n",
            "  Batch 1,440  of  4,500.    Elapsed: 0:16:42.\n",
            "  Batch 1,480  of  4,500.    Elapsed: 0:17:09.\n",
            "  Batch 1,520  of  4,500.    Elapsed: 0:17:37.\n",
            "  Batch 1,560  of  4,500.    Elapsed: 0:18:05.\n",
            "  Batch 1,600  of  4,500.    Elapsed: 0:18:33.\n",
            "  Batch 1,640  of  4,500.    Elapsed: 0:19:01.\n",
            "  Batch 1,680  of  4,500.    Elapsed: 0:19:29.\n",
            "  Batch 1,720  of  4,500.    Elapsed: 0:19:57.\n",
            "  Batch 1,760  of  4,500.    Elapsed: 0:20:24.\n",
            "  Batch 1,800  of  4,500.    Elapsed: 0:20:52.\n",
            "  Batch 1,840  of  4,500.    Elapsed: 0:21:20.\n",
            "  Batch 1,880  of  4,500.    Elapsed: 0:21:48.\n",
            "  Batch 1,920  of  4,500.    Elapsed: 0:22:16.\n",
            "  Batch 1,960  of  4,500.    Elapsed: 0:22:44.\n",
            "  Batch 2,000  of  4,500.    Elapsed: 0:23:12.\n",
            "  Batch 2,040  of  4,500.    Elapsed: 0:23:40.\n",
            "  Batch 2,080  of  4,500.    Elapsed: 0:24:07.\n",
            "  Batch 2,120  of  4,500.    Elapsed: 0:24:35.\n",
            "  Batch 2,160  of  4,500.    Elapsed: 0:25:03.\n",
            "  Batch 2,200  of  4,500.    Elapsed: 0:25:31.\n",
            "  Batch 2,240  of  4,500.    Elapsed: 0:25:59.\n",
            "  Batch 2,280  of  4,500.    Elapsed: 0:26:27.\n",
            "  Batch 2,320  of  4,500.    Elapsed: 0:26:55.\n",
            "  Batch 2,360  of  4,500.    Elapsed: 0:27:22.\n",
            "  Batch 2,400  of  4,500.    Elapsed: 0:27:50.\n",
            "  Batch 2,440  of  4,500.    Elapsed: 0:28:18.\n",
            "  Batch 2,480  of  4,500.    Elapsed: 0:28:46.\n",
            "  Batch 2,520  of  4,500.    Elapsed: 0:29:14.\n",
            "  Batch 2,560  of  4,500.    Elapsed: 0:29:42.\n",
            "  Batch 2,600  of  4,500.    Elapsed: 0:30:10.\n",
            "  Batch 2,640  of  4,500.    Elapsed: 0:30:38.\n",
            "  Batch 2,680  of  4,500.    Elapsed: 0:31:05.\n",
            "  Batch 2,720  of  4,500.    Elapsed: 0:31:33.\n",
            "  Batch 2,760  of  4,500.    Elapsed: 0:32:01.\n",
            "  Batch 2,800  of  4,500.    Elapsed: 0:32:29.\n",
            "  Batch 2,840  of  4,500.    Elapsed: 0:32:57.\n",
            "  Batch 2,880  of  4,500.    Elapsed: 0:33:25.\n",
            "  Batch 2,920  of  4,500.    Elapsed: 0:33:53.\n",
            "  Batch 2,960  of  4,500.    Elapsed: 0:34:21.\n",
            "  Batch 3,000  of  4,500.    Elapsed: 0:34:48.\n",
            "  Batch 3,040  of  4,500.    Elapsed: 0:35:16.\n",
            "  Batch 3,080  of  4,500.    Elapsed: 0:35:44.\n",
            "  Batch 3,120  of  4,500.    Elapsed: 0:36:12.\n",
            "  Batch 3,160  of  4,500.    Elapsed: 0:36:40.\n",
            "  Batch 3,200  of  4,500.    Elapsed: 0:37:08.\n",
            "  Batch 3,240  of  4,500.    Elapsed: 0:37:36.\n",
            "  Batch 3,280  of  4,500.    Elapsed: 0:38:04.\n",
            "  Batch 3,320  of  4,500.    Elapsed: 0:38:31.\n",
            "  Batch 3,360  of  4,500.    Elapsed: 0:38:59.\n",
            "  Batch 3,400  of  4,500.    Elapsed: 0:39:27.\n",
            "  Batch 3,440  of  4,500.    Elapsed: 0:39:55.\n",
            "  Batch 3,480  of  4,500.    Elapsed: 0:40:23.\n",
            "  Batch 3,520  of  4,500.    Elapsed: 0:40:51.\n",
            "  Batch 3,560  of  4,500.    Elapsed: 0:41:18.\n",
            "  Batch 3,600  of  4,500.    Elapsed: 0:41:46.\n",
            "  Batch 3,640  of  4,500.    Elapsed: 0:42:14.\n",
            "  Batch 3,680  of  4,500.    Elapsed: 0:42:42.\n",
            "  Batch 3,720  of  4,500.    Elapsed: 0:43:10.\n",
            "  Batch 3,760  of  4,500.    Elapsed: 0:43:38.\n",
            "  Batch 3,800  of  4,500.    Elapsed: 0:44:06.\n",
            "  Batch 3,840  of  4,500.    Elapsed: 0:44:33.\n",
            "  Batch 3,880  of  4,500.    Elapsed: 0:45:01.\n",
            "  Batch 3,920  of  4,500.    Elapsed: 0:45:29.\n",
            "  Batch 3,960  of  4,500.    Elapsed: 0:45:57.\n",
            "  Batch 4,000  of  4,500.    Elapsed: 0:46:25.\n",
            "  Batch 4,040  of  4,500.    Elapsed: 0:46:53.\n",
            "  Batch 4,080  of  4,500.    Elapsed: 0:47:20.\n",
            "  Batch 4,120  of  4,500.    Elapsed: 0:47:48.\n",
            "  Batch 4,160  of  4,500.    Elapsed: 0:48:16.\n",
            "  Batch 4,200  of  4,500.    Elapsed: 0:48:44.\n",
            "  Batch 4,240  of  4,500.    Elapsed: 0:49:12.\n",
            "  Batch 4,280  of  4,500.    Elapsed: 0:49:40.\n",
            "  Batch 4,320  of  4,500.    Elapsed: 0:50:08.\n",
            "  Batch 4,360  of  4,500.    Elapsed: 0:50:35.\n",
            "  Batch 4,400  of  4,500.    Elapsed: 0:51:03.\n",
            "  Batch 4,440  of  4,500.    Elapsed: 0:51:31.\n",
            "  Batch 4,480  of  4,500.    Elapsed: 0:51:59.\n",
            "\n",
            "  Average training loss: 0.10\n",
            "  Training epcoh took: 0:52:13\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy1: 0.95\n",
            "  Validation Loss: 0.17\n",
            "  Validation took: 0:01:48\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  4,500.    Elapsed: 0:00:28.\n",
            "  Batch    80  of  4,500.    Elapsed: 0:00:56.\n",
            "  Batch   120  of  4,500.    Elapsed: 0:01:24.\n",
            "  Batch   160  of  4,500.    Elapsed: 0:01:51.\n",
            "  Batch   200  of  4,500.    Elapsed: 0:02:19.\n",
            "  Batch   240  of  4,500.    Elapsed: 0:02:47.\n",
            "  Batch   280  of  4,500.    Elapsed: 0:03:15.\n",
            "  Batch   320  of  4,500.    Elapsed: 0:03:43.\n",
            "  Batch   360  of  4,500.    Elapsed: 0:04:11.\n",
            "  Batch   400  of  4,500.    Elapsed: 0:04:39.\n",
            "  Batch   440  of  4,500.    Elapsed: 0:05:06.\n",
            "  Batch   480  of  4,500.    Elapsed: 0:05:34.\n",
            "  Batch   520  of  4,500.    Elapsed: 0:06:02.\n",
            "  Batch   560  of  4,500.    Elapsed: 0:06:30.\n",
            "  Batch   600  of  4,500.    Elapsed: 0:06:58.\n",
            "  Batch   640  of  4,500.    Elapsed: 0:07:26.\n",
            "  Batch   680  of  4,500.    Elapsed: 0:07:54.\n",
            "  Batch   720  of  4,500.    Elapsed: 0:08:21.\n",
            "  Batch   760  of  4,500.    Elapsed: 0:08:49.\n",
            "  Batch   800  of  4,500.    Elapsed: 0:09:17.\n",
            "  Batch   840  of  4,500.    Elapsed: 0:09:45.\n",
            "  Batch   880  of  4,500.    Elapsed: 0:10:13.\n",
            "  Batch   920  of  4,500.    Elapsed: 0:10:41.\n",
            "  Batch   960  of  4,500.    Elapsed: 0:11:09.\n",
            "  Batch 1,000  of  4,500.    Elapsed: 0:11:36.\n",
            "  Batch 1,040  of  4,500.    Elapsed: 0:12:04.\n",
            "  Batch 1,080  of  4,500.    Elapsed: 0:12:32.\n",
            "  Batch 1,120  of  4,500.    Elapsed: 0:13:00.\n",
            "  Batch 1,160  of  4,500.    Elapsed: 0:13:28.\n",
            "  Batch 1,200  of  4,500.    Elapsed: 0:13:56.\n",
            "  Batch 1,240  of  4,500.    Elapsed: 0:14:24.\n",
            "  Batch 1,280  of  4,500.    Elapsed: 0:14:51.\n",
            "  Batch 1,320  of  4,500.    Elapsed: 0:15:19.\n",
            "  Batch 1,360  of  4,500.    Elapsed: 0:15:47.\n",
            "  Batch 1,400  of  4,500.    Elapsed: 0:16:15.\n",
            "  Batch 1,440  of  4,500.    Elapsed: 0:16:43.\n",
            "  Batch 1,480  of  4,500.    Elapsed: 0:17:11.\n",
            "  Batch 1,520  of  4,500.    Elapsed: 0:17:38.\n",
            "  Batch 1,560  of  4,500.    Elapsed: 0:18:06.\n",
            "  Batch 1,600  of  4,500.    Elapsed: 0:18:34.\n",
            "  Batch 1,640  of  4,500.    Elapsed: 0:19:02.\n",
            "  Batch 1,680  of  4,500.    Elapsed: 0:19:30.\n",
            "  Batch 1,720  of  4,500.    Elapsed: 0:19:58.\n",
            "  Batch 1,760  of  4,500.    Elapsed: 0:20:26.\n",
            "  Batch 1,800  of  4,500.    Elapsed: 0:20:53.\n",
            "  Batch 1,840  of  4,500.    Elapsed: 0:21:21.\n",
            "  Batch 1,880  of  4,500.    Elapsed: 0:21:49.\n",
            "  Batch 1,920  of  4,500.    Elapsed: 0:22:17.\n",
            "  Batch 1,960  of  4,500.    Elapsed: 0:22:45.\n",
            "  Batch 2,000  of  4,500.    Elapsed: 0:23:13.\n",
            "  Batch 2,040  of  4,500.    Elapsed: 0:23:41.\n",
            "  Batch 2,080  of  4,500.    Elapsed: 0:24:09.\n",
            "  Batch 2,120  of  4,500.    Elapsed: 0:24:36.\n",
            "  Batch 2,160  of  4,500.    Elapsed: 0:25:04.\n",
            "  Batch 2,200  of  4,500.    Elapsed: 0:25:32.\n",
            "  Batch 2,240  of  4,500.    Elapsed: 0:26:00.\n",
            "  Batch 2,280  of  4,500.    Elapsed: 0:26:28.\n",
            "  Batch 2,320  of  4,500.    Elapsed: 0:26:56.\n",
            "  Batch 2,360  of  4,500.    Elapsed: 0:27:23.\n",
            "  Batch 2,400  of  4,500.    Elapsed: 0:27:51.\n",
            "  Batch 2,440  of  4,500.    Elapsed: 0:28:19.\n",
            "  Batch 2,480  of  4,500.    Elapsed: 0:28:47.\n",
            "  Batch 2,520  of  4,500.    Elapsed: 0:29:15.\n",
            "  Batch 2,560  of  4,500.    Elapsed: 0:29:43.\n",
            "  Batch 2,600  of  4,500.    Elapsed: 0:30:11.\n",
            "  Batch 2,640  of  4,500.    Elapsed: 0:30:38.\n",
            "  Batch 2,680  of  4,500.    Elapsed: 0:31:06.\n",
            "  Batch 2,720  of  4,500.    Elapsed: 0:31:34.\n",
            "  Batch 2,760  of  4,500.    Elapsed: 0:32:02.\n",
            "  Batch 2,800  of  4,500.    Elapsed: 0:32:30.\n",
            "  Batch 2,840  of  4,500.    Elapsed: 0:32:58.\n",
            "  Batch 2,880  of  4,500.    Elapsed: 0:33:26.\n",
            "  Batch 2,920  of  4,500.    Elapsed: 0:33:53.\n",
            "  Batch 2,960  of  4,500.    Elapsed: 0:34:21.\n",
            "  Batch 3,000  of  4,500.    Elapsed: 0:34:49.\n",
            "  Batch 3,040  of  4,500.    Elapsed: 0:35:17.\n",
            "  Batch 3,080  of  4,500.    Elapsed: 0:35:45.\n",
            "  Batch 3,120  of  4,500.    Elapsed: 0:36:12.\n",
            "  Batch 3,160  of  4,500.    Elapsed: 0:36:40.\n",
            "  Batch 3,200  of  4,500.    Elapsed: 0:37:08.\n",
            "  Batch 3,240  of  4,500.    Elapsed: 0:37:36.\n",
            "  Batch 3,280  of  4,500.    Elapsed: 0:38:04.\n",
            "  Batch 3,320  of  4,500.    Elapsed: 0:38:32.\n",
            "  Batch 3,360  of  4,500.    Elapsed: 0:38:59.\n",
            "  Batch 3,400  of  4,500.    Elapsed: 0:39:27.\n",
            "  Batch 3,440  of  4,500.    Elapsed: 0:39:55.\n",
            "  Batch 3,480  of  4,500.    Elapsed: 0:40:23.\n",
            "  Batch 3,520  of  4,500.    Elapsed: 0:40:51.\n",
            "  Batch 3,560  of  4,500.    Elapsed: 0:41:18.\n",
            "  Batch 3,600  of  4,500.    Elapsed: 0:41:46.\n",
            "  Batch 3,640  of  4,500.    Elapsed: 0:42:14.\n",
            "  Batch 3,680  of  4,500.    Elapsed: 0:42:42.\n",
            "  Batch 3,720  of  4,500.    Elapsed: 0:43:10.\n",
            "  Batch 3,760  of  4,500.    Elapsed: 0:43:38.\n",
            "  Batch 3,800  of  4,500.    Elapsed: 0:44:05.\n",
            "  Batch 3,840  of  4,500.    Elapsed: 0:44:33.\n",
            "  Batch 3,880  of  4,500.    Elapsed: 0:45:01.\n",
            "  Batch 3,920  of  4,500.    Elapsed: 0:45:29.\n",
            "  Batch 3,960  of  4,500.    Elapsed: 0:45:57.\n",
            "  Batch 4,000  of  4,500.    Elapsed: 0:46:25.\n",
            "  Batch 4,040  of  4,500.    Elapsed: 0:46:53.\n",
            "  Batch 4,080  of  4,500.    Elapsed: 0:47:20.\n",
            "  Batch 4,120  of  4,500.    Elapsed: 0:47:48.\n",
            "  Batch 4,160  of  4,500.    Elapsed: 0:48:16.\n",
            "  Batch 4,200  of  4,500.    Elapsed: 0:48:44.\n",
            "  Batch 4,240  of  4,500.    Elapsed: 0:49:12.\n",
            "  Batch 4,280  of  4,500.    Elapsed: 0:49:40.\n",
            "  Batch 4,320  of  4,500.    Elapsed: 0:50:08.\n",
            "  Batch 4,360  of  4,500.    Elapsed: 0:50:35.\n",
            "  Batch 4,400  of  4,500.    Elapsed: 0:51:03.\n",
            "  Batch 4,440  of  4,500.    Elapsed: 0:51:31.\n",
            "  Batch 4,480  of  4,500.    Elapsed: 0:51:59.\n",
            "\n",
            "  Average training loss: 0.07\n",
            "  Training epcoh took: 0:52:13\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy1: 0.96\n",
            "  Validation Loss: 0.18\n",
            "  Validation took: 0:01:48\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  4,500.    Elapsed: 0:00:28.\n",
            "  Batch    80  of  4,500.    Elapsed: 0:00:56.\n",
            "  Batch   120  of  4,500.    Elapsed: 0:01:24.\n",
            "  Batch   160  of  4,500.    Elapsed: 0:01:51.\n",
            "  Batch   200  of  4,500.    Elapsed: 0:02:19.\n",
            "  Batch   240  of  4,500.    Elapsed: 0:02:47.\n",
            "  Batch   280  of  4,500.    Elapsed: 0:03:15.\n",
            "  Batch   320  of  4,500.    Elapsed: 0:03:43.\n",
            "  Batch   360  of  4,500.    Elapsed: 0:04:11.\n",
            "  Batch   400  of  4,500.    Elapsed: 0:04:39.\n",
            "  Batch   440  of  4,500.    Elapsed: 0:05:06.\n",
            "  Batch   480  of  4,500.    Elapsed: 0:05:34.\n",
            "  Batch   520  of  4,500.    Elapsed: 0:06:02.\n",
            "  Batch   560  of  4,500.    Elapsed: 0:06:30.\n",
            "  Batch   600  of  4,500.    Elapsed: 0:06:58.\n",
            "  Batch   640  of  4,500.    Elapsed: 0:07:26.\n",
            "  Batch   680  of  4,500.    Elapsed: 0:07:54.\n",
            "  Batch   720  of  4,500.    Elapsed: 0:08:21.\n",
            "  Batch   760  of  4,500.    Elapsed: 0:08:49.\n",
            "  Batch   800  of  4,500.    Elapsed: 0:09:17.\n",
            "  Batch   840  of  4,500.    Elapsed: 0:09:45.\n",
            "  Batch   880  of  4,500.    Elapsed: 0:10:13.\n",
            "  Batch   920  of  4,500.    Elapsed: 0:10:41.\n",
            "  Batch   960  of  4,500.    Elapsed: 0:11:09.\n",
            "  Batch 1,000  of  4,500.    Elapsed: 0:11:36.\n",
            "  Batch 1,040  of  4,500.    Elapsed: 0:12:04.\n",
            "  Batch 1,080  of  4,500.    Elapsed: 0:12:32.\n",
            "  Batch 1,120  of  4,500.    Elapsed: 0:13:00.\n",
            "  Batch 1,160  of  4,500.    Elapsed: 0:13:28.\n",
            "  Batch 1,200  of  4,500.    Elapsed: 0:13:56.\n",
            "  Batch 1,240  of  4,500.    Elapsed: 0:14:24.\n",
            "  Batch 1,280  of  4,500.    Elapsed: 0:14:51.\n",
            "  Batch 1,320  of  4,500.    Elapsed: 0:15:19.\n",
            "  Batch 1,360  of  4,500.    Elapsed: 0:15:47.\n",
            "  Batch 1,400  of  4,500.    Elapsed: 0:16:15.\n",
            "  Batch 1,440  of  4,500.    Elapsed: 0:16:43.\n",
            "  Batch 1,480  of  4,500.    Elapsed: 0:17:11.\n",
            "  Batch 1,520  of  4,500.    Elapsed: 0:17:39.\n",
            "  Batch 1,560  of  4,500.    Elapsed: 0:18:06.\n",
            "  Batch 1,600  of  4,500.    Elapsed: 0:18:34.\n",
            "  Batch 1,640  of  4,500.    Elapsed: 0:19:02.\n",
            "  Batch 1,680  of  4,500.    Elapsed: 0:19:30.\n",
            "  Batch 1,720  of  4,500.    Elapsed: 0:19:58.\n",
            "  Batch 1,760  of  4,500.    Elapsed: 0:20:26.\n",
            "  Batch 1,800  of  4,500.    Elapsed: 0:20:53.\n",
            "  Batch 1,840  of  4,500.    Elapsed: 0:21:21.\n",
            "  Batch 1,880  of  4,500.    Elapsed: 0:21:49.\n",
            "  Batch 1,920  of  4,500.    Elapsed: 0:22:17.\n",
            "  Batch 1,960  of  4,500.    Elapsed: 0:22:45.\n",
            "  Batch 2,000  of  4,500.    Elapsed: 0:23:13.\n",
            "  Batch 2,040  of  4,500.    Elapsed: 0:23:41.\n",
            "  Batch 2,080  of  4,500.    Elapsed: 0:24:08.\n",
            "  Batch 2,120  of  4,500.    Elapsed: 0:24:36.\n",
            "  Batch 2,160  of  4,500.    Elapsed: 0:25:04.\n",
            "  Batch 2,200  of  4,500.    Elapsed: 0:25:32.\n",
            "  Batch 2,240  of  4,500.    Elapsed: 0:26:00.\n",
            "  Batch 2,280  of  4,500.    Elapsed: 0:26:28.\n",
            "  Batch 2,320  of  4,500.    Elapsed: 0:26:55.\n",
            "  Batch 2,360  of  4,500.    Elapsed: 0:27:23.\n",
            "  Batch 2,400  of  4,500.    Elapsed: 0:27:51.\n",
            "  Batch 2,440  of  4,500.    Elapsed: 0:28:19.\n",
            "  Batch 2,480  of  4,500.    Elapsed: 0:28:47.\n",
            "  Batch 2,520  of  4,500.    Elapsed: 0:29:15.\n",
            "  Batch 2,560  of  4,500.    Elapsed: 0:29:42.\n",
            "  Batch 2,600  of  4,500.    Elapsed: 0:30:10.\n",
            "  Batch 2,640  of  4,500.    Elapsed: 0:30:38.\n",
            "  Batch 2,680  of  4,500.    Elapsed: 0:31:06.\n",
            "  Batch 2,720  of  4,500.    Elapsed: 0:31:34.\n",
            "  Batch 2,760  of  4,500.    Elapsed: 0:32:02.\n",
            "  Batch 2,800  of  4,500.    Elapsed: 0:32:30.\n",
            "  Batch 2,840  of  4,500.    Elapsed: 0:32:57.\n",
            "  Batch 2,880  of  4,500.    Elapsed: 0:33:25.\n",
            "  Batch 2,920  of  4,500.    Elapsed: 0:33:53.\n",
            "  Batch 2,960  of  4,500.    Elapsed: 0:34:21.\n",
            "  Batch 3,000  of  4,500.    Elapsed: 0:34:49.\n",
            "  Batch 3,040  of  4,500.    Elapsed: 0:35:17.\n",
            "  Batch 3,080  of  4,500.    Elapsed: 0:35:45.\n",
            "  Batch 3,120  of  4,500.    Elapsed: 0:36:12.\n",
            "  Batch 3,160  of  4,500.    Elapsed: 0:36:40.\n",
            "  Batch 3,200  of  4,500.    Elapsed: 0:37:08.\n",
            "  Batch 3,240  of  4,500.    Elapsed: 0:37:36.\n",
            "  Batch 3,280  of  4,500.    Elapsed: 0:38:04.\n",
            "  Batch 3,320  of  4,500.    Elapsed: 0:38:32.\n",
            "  Batch 3,360  of  4,500.    Elapsed: 0:39:00.\n",
            "  Batch 3,400  of  4,500.    Elapsed: 0:39:28.\n",
            "  Batch 3,440  of  4,500.    Elapsed: 0:39:55.\n",
            "  Batch 3,480  of  4,500.    Elapsed: 0:40:23.\n",
            "  Batch 3,520  of  4,500.    Elapsed: 0:40:51.\n",
            "  Batch 3,560  of  4,500.    Elapsed: 0:41:19.\n",
            "  Batch 3,600  of  4,500.    Elapsed: 0:41:47.\n",
            "  Batch 3,640  of  4,500.    Elapsed: 0:42:15.\n",
            "  Batch 3,680  of  4,500.    Elapsed: 0:42:43.\n",
            "  Batch 3,720  of  4,500.    Elapsed: 0:43:10.\n",
            "  Batch 3,760  of  4,500.    Elapsed: 0:43:38.\n",
            "  Batch 3,800  of  4,500.    Elapsed: 0:44:06.\n",
            "  Batch 3,840  of  4,500.    Elapsed: 0:44:34.\n",
            "  Batch 3,880  of  4,500.    Elapsed: 0:45:02.\n",
            "  Batch 3,920  of  4,500.    Elapsed: 0:45:30.\n",
            "  Batch 3,960  of  4,500.    Elapsed: 0:45:58.\n",
            "  Batch 4,000  of  4,500.    Elapsed: 0:46:25.\n",
            "  Batch 4,040  of  4,500.    Elapsed: 0:46:53.\n",
            "  Batch 4,080  of  4,500.    Elapsed: 0:47:21.\n",
            "  Batch 4,120  of  4,500.    Elapsed: 0:47:49.\n",
            "  Batch 4,160  of  4,500.    Elapsed: 0:48:17.\n",
            "  Batch 4,200  of  4,500.    Elapsed: 0:48:45.\n",
            "  Batch 4,240  of  4,500.    Elapsed: 0:49:12.\n",
            "  Batch 4,280  of  4,500.    Elapsed: 0:49:40.\n",
            "  Batch 4,320  of  4,500.    Elapsed: 0:50:08.\n",
            "  Batch 4,360  of  4,500.    Elapsed: 0:50:36.\n",
            "  Batch 4,400  of  4,500.    Elapsed: 0:51:04.\n",
            "  Batch 4,440  of  4,500.    Elapsed: 0:51:32.\n",
            "  Batch 4,480  of  4,500.    Elapsed: 0:52:00.\n",
            "\n",
            "  Average training loss: 0.05\n",
            "  Training epcoh took: 0:52:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy1: 0.96\n",
            "  Validation Loss: 0.20\n",
            "  Validation took: 0:01:48\n",
            "\n",
            "Training complete!\n",
            "Total training took 3:36:11 (h:mm:ss)\n"
          ]
        }
      ],
      "source": [
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    # Perform one full pass over the training set.\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # print(b_labels.shape)\n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "        result = model(b_input_ids, \n",
        "                       token_type_ids=None, \n",
        "                       attention_mask=b_input_mask, \n",
        "                       return_dict=True)\n",
        "        label1_preds = result[\"logits\"][:, :6]\n",
        "        label1_loss = torch.nn.functional.cross_entropy(label1_preds, b_labels[:, 0])\n",
        "\n",
        "\n",
        "        loss = label1_loss\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    total_eval_accuracy1 = 0\n",
        "    total_eval_accuracy2 = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        with torch.no_grad():        \n",
        "\n",
        "            result = model(b_input_ids, \n",
        "                           token_type_ids=None, \n",
        "                           attention_mask=b_input_mask,\n",
        "                           return_dict=True)\n",
        "\n",
        "        label1_preds = result[\"logits\"][:, :label_1_num_classes]\n",
        "        label1_loss = torch.nn.functional.cross_entropy(label1_preds, b_labels[:, 0])\n",
        "\n",
        "\n",
        "        loss = label1_loss \n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        label1_preds = label1_preds.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        eval_1 = flat_accuracy(label1_preds,label_ids)\n",
        "        total_eval_accuracy1+=eval_1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy1 = total_eval_accuracy1 / len(validation_dataloader)\n",
        "    print(\"  Accuracy1: {0:.2f}\".format(avg_val_accuracy1))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur. Label1.': avg_val_accuracy1,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "    path = \"epoch_\"+str(epoch_i)+\"_check.pth\"\n",
        "    torch.save(model.state_dict(), path)\n",
        " \n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qmt6gOJM1Tir"
      },
      "source": [
        "# Calculating testing accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-15jhi61KOL",
        "outputId": "a1836f0f-145b-48bb-e1c0-79ae9b1fdf0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of test sentences: 40,000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data={'sentence':X_test,'label':y_test}\n",
        "df=pd.DataFrame(data, columns =['label','sentence']) \n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values\n",
        "\n",
        "label_1_num_classes = 2\n",
        "\n",
        "# from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# label1_encoder = LabelEncoder()\n",
        "\n",
        "# label1 = [item[0] for item in labels]\n",
        "# label1 = label1_encoder.fit_transform(label1)\n",
        "\n",
        "label1 = torch.LongTensor(labels)\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for sent in sentences:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                sent,add_special_tokens = True,max_length = 512,pad_to_max_length = True, return_attention_mask = True,return_tensors = 'pt',)\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "all_labels = torch.stack([label1], dim=1)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, all_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, shuffle=False, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9RkqHLt1ZBe",
        "outputId": "a0a416f3-0f0f-4da1-905a-19f627c490c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels for 40,000 test sentences...\n",
            "\n",
            "Number of Label1 correctly predicted: 38415\n",
            "Number of Label1 misclassify: 1585\n",
            "Label1 Testing Accuracy: 0.96\n"
          ]
        }
      ],
      "source": [
        "# Prediction on test set\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "prediction_list = []\n",
        "real_list=[]\n",
        "accuracy1 = 0\n",
        "total_count = 0\n",
        "misclassify1=0\n",
        "misclassify_data=[]\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict\n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions.\n",
        "      result = model(b_input_ids, \n",
        "                     token_type_ids=None, \n",
        "                     attention_mask=b_input_mask,\n",
        "                     return_dict=True)\n",
        "\n",
        "  #logits = result.logits\n",
        "  label1_preds = result[\"logits\"][:, :label_1_num_classes]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  label1_preds = label1_preds.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "  label1_preds=np.argmax(label1_preds,axis=1)\n",
        "  label_ids = label_ids.flatten()\n",
        "\n",
        "  for i in range(len(label_ids)):\n",
        "    prediction_list.append(label1_preds[i])\n",
        "    real_list.append(label_ids[i])\n",
        "    if(label1_preds[i]==label_ids[i]):\n",
        "      accuracy1+=1\n",
        "    else:\n",
        "      misclassify1+=1\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print(\"Number of Label1 correctly predicted: \"+str(accuracy1))\n",
        "print(\"Number of Label1 misclassify: \"+str(misclassify1))\n",
        "\n",
        "print(\"Label1 Testing Accuracy: {:.2f}\".format(accuracy1/(accuracy1+misclassify1) ) )\n",
        "bert_singlelabel_accuracy1 = accuracy1/(accuracy1+misclassify1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "1-LGRUcagaEG",
        "outputId": "70da97ab-af40-4338-d271-9b0d8cfe1e33"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f88f3ddf350>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "sns.heatmap(confusion_matrix(real_list,prediction_list), annot=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02b21f78bab24a5fbd0fa490d6b0d883": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76d7ac888798422fb1d9c19fe34cbf25",
            "placeholder": "​",
            "style": "IPY_MODEL_d2515affaad64fd090c18dddec605c61",
            "value": " 481/481 [00:00&lt;00:00, 17.9kB/s]"
          }
        },
        "07945106a62d431abaef733532b21cfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e89a5e0c424458ba2bab68ecaf72f3d",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_65b1232c0f5b47d2a8f907342529b9ec",
            "value": 456318
          }
        },
        "0b08b69721f143efb0b210a0c6ca37e4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fa733348c3a4df8873e28c5822357b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_21006283c6d64ec8abff78aeccde9f49",
              "IPY_MODEL_3c343821bab447c2b9a4fc4d6435ec3e",
              "IPY_MODEL_eaacb8a8f1ea4ec180f012bfb70176e3"
            ],
            "layout": "IPY_MODEL_20f8a8490f56441d9764132cf53ddfcb"
          }
        },
        "130e497ad2c9449986ac66101d459e11": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cc9866a8acd44c9ba2ebb01499d1163": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f9ec2448f734b35a14d5b67159636ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d2951498bd774b058e55f744c831a97f",
              "IPY_MODEL_580540de040c49369350c981c638097c",
              "IPY_MODEL_856592d5d8634ba8a1988673bc7600c6"
            ],
            "layout": "IPY_MODEL_e2b150cd67444738bb14e61becb8a4f0"
          }
        },
        "20f8a8490f56441d9764132cf53ddfcb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21006283c6d64ec8abff78aeccde9f49": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d85213a949a4cda8e3af356a6765943",
            "placeholder": "​",
            "style": "IPY_MODEL_36a8f86fbabc47d198c675f23e3b9d05",
            "value": "Downloading: 100%"
          }
        },
        "22baf62f26bd44f3b052ba12efb53bb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3391af5bfb1943d6b830389bed4a0315": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3655fa1c25714391b15483ee803e2db2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36a8f86fbabc47d198c675f23e3b9d05": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3bc6747f96db4cdb940695f4181e85b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7c396ed308d2464f943c67986da7adab",
              "IPY_MODEL_aab223fc56bb45a39d945ae7cc9f245d",
              "IPY_MODEL_87ed97427e5d4b4a872c009fdc9b82b9"
            ],
            "layout": "IPY_MODEL_45694a35b5cd458e9e907d6b724db052"
          }
        },
        "3c03d17b258b4c53a3fbc4b8642622c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c343821bab447c2b9a4fc4d6435ec3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ee3fb012abc4163ad8a1823e44fcf95",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_45ce266fef514f8a9e92c5dd20fbb980",
            "value": 1355863
          }
        },
        "3d85213a949a4cda8e3af356a6765943": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41434b4e593344dea17555c76c50d884": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45694a35b5cd458e9e907d6b724db052": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45ce266fef514f8a9e92c5dd20fbb980": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4ee3fb012abc4163ad8a1823e44fcf95": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52860b9c009c41cd93aaf2c1cdb1fe2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "580540de040c49369350c981c638097c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b08b69721f143efb0b210a0c6ca37e4",
            "max": 501200538,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a921172a574c4aebb5e0ca4426f41fd7",
            "value": 501200538
          }
        },
        "593adab5fe234b778d00d174096b3576": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e1ed889061f480abdbe780dc21e2e92": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e27135b02e04bbdbb91806023e62b8d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "606b2f6f828e4e14a62dd23f4a253dda": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41434b4e593344dea17555c76c50d884",
            "placeholder": "​",
            "style": "IPY_MODEL_3c03d17b258b4c53a3fbc4b8642622c7",
            "value": "Downloading: 100%"
          }
        },
        "61e9d4e120bb41e3bef85b9e1017bdf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e27135b02e04bbdbb91806023e62b8d",
            "placeholder": "​",
            "style": "IPY_MODEL_95b5af8c1f284f608237a4d482bbe4d0",
            "value": "Downloading: 100%"
          }
        },
        "6515ffbe08894525bdc38fa035e59ce8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "65b1232c0f5b47d2a8f907342529b9ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "70b581026b4d4bf1a5f67d0fa4d71728": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5efa6fc4f9b4c07aa52390dfd3e62cc",
            "placeholder": "​",
            "style": "IPY_MODEL_f2ee44c67e1f48fdb7bd6cacffea65dc",
            "value": " 456k/456k [00:01&lt;00:00, 530kB/s]"
          }
        },
        "7115292ee45f4d65807c7d00ebb73d5a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74ad18e54a5a4fb4a8a1454fd1749570": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76d7ac888798422fb1d9c19fe34cbf25": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c396ed308d2464f943c67986da7adab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8fb37721eae4af49bd36e0f9890d24d",
            "placeholder": "​",
            "style": "IPY_MODEL_6515ffbe08894525bdc38fa035e59ce8",
            "value": "Downloading: 100%"
          }
        },
        "856592d5d8634ba8a1988673bc7600c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7115292ee45f4d65807c7d00ebb73d5a",
            "placeholder": "​",
            "style": "IPY_MODEL_1cc9866a8acd44c9ba2ebb01499d1163",
            "value": " 501M/501M [00:08&lt;00:00, 62.8MB/s]"
          }
        },
        "87ed97427e5d4b4a872c009fdc9b82b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3391af5bfb1943d6b830389bed4a0315",
            "placeholder": "​",
            "style": "IPY_MODEL_3655fa1c25714391b15483ee803e2db2",
            "value": " 899k/899k [00:01&lt;00:00, 930kB/s]"
          }
        },
        "8dad4f6b39374037bdf40573fb056900": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ee3e2f66370415e9946452e6e16aa25": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "95b5af8c1f284f608237a4d482bbe4d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e89a5e0c424458ba2bab68ecaf72f3d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2ed3110a1b9455d9cbb29413380278c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74ad18e54a5a4fb4a8a1454fd1749570",
            "max": 481,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_22baf62f26bd44f3b052ba12efb53bb7",
            "value": 481
          }
        },
        "a8d9f3dbfc5848f58ecb03490f5bf2db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_61e9d4e120bb41e3bef85b9e1017bdf6",
              "IPY_MODEL_a2ed3110a1b9455d9cbb29413380278c",
              "IPY_MODEL_02b21f78bab24a5fbd0fa490d6b0d883"
            ],
            "layout": "IPY_MODEL_b7eef61f25f84c9c9dbf73b5bbbadfac"
          }
        },
        "a921172a574c4aebb5e0ca4426f41fd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aab223fc56bb45a39d945ae7cc9f245d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8dad4f6b39374037bdf40573fb056900",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8ee3e2f66370415e9946452e6e16aa25",
            "value": 898823
          }
        },
        "b7eef61f25f84c9c9dbf73b5bbbadfac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8fb37721eae4af49bd36e0f9890d24d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcd0457a22ec4211a3db41e141e053f6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2515affaad64fd090c18dddec605c61": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2951498bd774b058e55f744c831a97f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_130e497ad2c9449986ac66101d459e11",
            "placeholder": "​",
            "style": "IPY_MODEL_593adab5fe234b778d00d174096b3576",
            "value": "Downloading: 100%"
          }
        },
        "d5efa6fc4f9b4c07aa52390dfd3e62cc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc1a268fadff4da681885addd39a5d27": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_606b2f6f828e4e14a62dd23f4a253dda",
              "IPY_MODEL_07945106a62d431abaef733532b21cfb",
              "IPY_MODEL_70b581026b4d4bf1a5f67d0fa4d71728"
            ],
            "layout": "IPY_MODEL_bcd0457a22ec4211a3db41e141e053f6"
          }
        },
        "e2b150cd67444738bb14e61becb8a4f0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eaacb8a8f1ea4ec180f012bfb70176e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e1ed889061f480abdbe780dc21e2e92",
            "placeholder": "​",
            "style": "IPY_MODEL_52860b9c009c41cd93aaf2c1cdb1fe2a",
            "value": " 1.36M/1.36M [00:01&lt;00:00, 900kB/s]"
          }
        },
        "f2ee44c67e1f48fdb7bd6cacffea65dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}