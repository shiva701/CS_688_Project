{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "202286685d824e59abb841ca52aa74c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_502f101cc8a24098b26b11e2b6fbfd00",
              "IPY_MODEL_16cab721a3944034910b21679ff1cc06",
              "IPY_MODEL_3fd783b454d04edf82780d57a7762ad1"
            ],
            "layout": "IPY_MODEL_3e14bddc8b7847bb96521e61d8159580"
          }
        },
        "502f101cc8a24098b26b11e2b6fbfd00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e30590efae443da84a0677bdf3195e9",
            "placeholder": "​",
            "style": "IPY_MODEL_23da1fb251b64a15b3f026f1e1011062",
            "value": "Downloading: 100%"
          }
        },
        "16cab721a3944034910b21679ff1cc06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1fbf539137d4887b0a384ac7d58bff5",
            "max": 501200538,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d866695c3c9344a9ac250b43f89e1388",
            "value": 501200538
          }
        },
        "3fd783b454d04edf82780d57a7762ad1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_699a4c16ade44646a02786f88bbeacbf",
            "placeholder": "​",
            "style": "IPY_MODEL_cb3be4a608fa4c3aac58c9e1fde1e2b8",
            "value": " 501M/501M [00:08&lt;00:00, 65.1MB/s]"
          }
        },
        "3e14bddc8b7847bb96521e61d8159580": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e30590efae443da84a0677bdf3195e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23da1fb251b64a15b3f026f1e1011062": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1fbf539137d4887b0a384ac7d58bff5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d866695c3c9344a9ac250b43f89e1388": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "699a4c16ade44646a02786f88bbeacbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb3be4a608fa4c3aac58c9e1fde1e2b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Loading Data"
      ],
      "metadata": {
        "id": "T_tfnIWPC0mF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rx-xRH9IuK87",
        "outputId": "f936caff-9cba-4a37-847d-cedb5da52801"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/CS-688_Project/IMDB/IMDB Dataset.csv\")"
      ],
      "metadata": {
        "id": "cHpohSmgwLjP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data=(data.iloc[:100,:])"
      ],
      "metadata": {
        "id": "Rpi5rlNv0wzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Libraries"
      ],
      "metadata": {
        "id": "K9yiifL5wZ4C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Doing some experimentations I notice that there was a CUDA error coming with older version of PyTorch, so it's advisable to upgrade PyTorch version."
      ],
      "metadata": {
        "id": "W0-gsmwhwZ4E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade torch"
      ],
      "metadata": {
        "id": "lzehLcpzwZ4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8e2eede-1aa7-46fa-90bf-7a90ce3ded02",
        "id": "MbNgyDqzwZ4G"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5 MB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 89.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 57.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.10.1 tokenizers-0.13.2 transformers-4.24.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import random\n",
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from transformers import RobertaTokenizerFast, RobertaForSequenceClassification\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig"
      ],
      "metadata": {
        "id": "RdLBxD98wZ4H"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bac2f119-49b6-4983-8a60-24fb01003487",
        "id": "i06kd8rvwZ4I"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: A100-SXM4-40GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Processing Data"
      ],
      "metadata": {
        "id": "zCRhKOoNwgte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=data"
      ],
      "metadata": {
        "id": "LYW46GUXurbB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = df['review'].tolist()\n",
        "label1 = df['sentiment'].tolist()\n",
        "\n",
        "c = Counter(label1)\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "Intent = []\n",
        "Occurance = []\n",
        "for i in c.items():\n",
        "  Intent.append(i[0])\n",
        "  Occurance.append(i[1])\n",
        "ax.bar(Intent,Occurance,color=(0.2, 0.4, 0.6, 0.6))  \n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "1e92facc-1341-4a0c-b42b-ffbc94af42ba",
        "id": "vIrByRkgwgth"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {
        "id": "_MkV9gziw8-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dic={'positive':0,'negative':1}\n",
        "ans={0:'positive',1:'negative'}\n",
        "\n",
        "classes_number = len(dic)\n",
        "\n",
        "print(\"classes_number:\",classes_number)"
      ],
      "metadata": {
        "id": "2MOfbnVZN-yh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afff3690-64d1-4536-ec57-9300c8cad21d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classes_number: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels=data['sentiment']\n",
        "sentence=data['review']\n",
        "\n",
        "for i in range(len(labels)):\n",
        "  labels[i]=dic[labels[i]]"
      ],
      "metadata": {
        "id": "FAnL8ekpu9Cj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(label1)):\n",
        " label1[i]=dic[label1[i]]\n",
        "\n",
        "data={'sentence':sentence,'label1':labels}\n",
        "df=pd.DataFrame(data)\n",
        "print(len(df))\n",
        "df=df.drop_duplicates()\n",
        "print(len(df))"
      ],
      "metadata": {
        "id": "0kzB-cbMOyVJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7c16c35-44d9-4f4a-ab61-6d387ae2f044"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50000\n",
            "49582\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(sentence, label1, test_size = 0.20, random_state = 0)"
      ],
      "metadata": {
        "id": "v_uwuxrGwSkj"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = X_train\n",
        "labels = y_train"
      ],
      "metadata": {
        "id": "qs928X_GwSjJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_1_num_classes = classes_number\n",
        "\n",
        "label1 = torch.LongTensor(labels)"
      ],
      "metadata": {
        "id": "IkUNRhFIwciE"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading RoBERTa Model and Creating Data Frame"
      ],
      "metadata": {
        "id": "bDawdeDgxy-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Loading RoBERTa tokenizer...')\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base', do_lower_case=True)\n",
        "\n",
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDsAxHLAxwUX",
        "outputId": "06a373d6-3c72-412c-fc75-77e6c446b616"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading RoBERTa tokenizer...\n",
            " Original:  One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\n",
            "Tokenized:  ['One', 'Ġof', 'Ġthe', 'Ġother', 'Ġreviewers', 'Ġhas', 'Ġmentioned', 'Ġthat', 'Ġafter', 'Ġwatching', 'Ġjust', 'Ġ1', 'ĠOz', 'Ġepisode', 'Ġyou', \"'ll\", 'Ġbe', 'Ġhooked', '.', 'ĠThey', 'Ġare', 'Ġright', ',', 'Ġas', 'Ġthis', 'Ġis', 'Ġexactly', 'Ġwhat', 'Ġhappened', 'Ġwith', 'Ġme', '.<', 'br', 'Ġ/', '><', 'br', 'Ġ/>', 'The', 'Ġfirst', 'Ġthing', 'Ġthat', 'Ġstruck', 'Ġme', 'Ġabout', 'ĠOz', 'Ġwas', 'Ġits', 'Ġbrutality', 'Ġand', 'Ġunfl', 'inch', 'ing', 'Ġscenes', 'Ġof', 'Ġviolence', ',', 'Ġwhich', 'Ġset', 'Ġin', 'Ġright', 'Ġfrom', 'Ġthe', 'Ġword', 'ĠGO', '.', 'ĠTrust', 'Ġme', ',', 'Ġthis', 'Ġis', 'Ġnot', 'Ġa', 'Ġshow', 'Ġfor', 'Ġthe', 'Ġfaint', 'Ġheart', 'ed', 'Ġor', 'Ġtimid', '.', 'ĠThis', 'Ġshow', 'Ġpulls', 'Ġno', 'Ġpunches', 'Ġwith', 'Ġregards', 'Ġto', 'Ġdrugs', ',', 'Ġsex', 'Ġor', 'Ġviolence', '.', 'ĠIts', 'Ġis', 'Ġhardcore', ',', 'Ġin', 'Ġthe', 'Ġclassic', 'Ġuse', 'Ġof', 'Ġthe', 'Ġword', '.<', 'br', 'Ġ/', '><', 'br', 'Ġ/>', 'It', 'Ġis', 'Ġcalled', 'ĠO', 'Z', 'Ġas', 'Ġthat', 'Ġis', 'Ġthe', 'Ġnickname', 'Ġgiven', 'Ġto', 'Ġthe', 'ĠOswald', 'ĠMaximum', 'ĠSecurity', 'ĠState', 'ĠPen', 'itent', 'ary', '.', 'ĠIt', 'Ġfocuses', 'Ġmainly', 'Ġon', 'ĠEmerald', 'ĠCity', ',', 'Ġan', 'Ġexperimental', 'Ġsection', 'Ġof', 'Ġthe', 'Ġprison', 'Ġwhere', 'Ġall', 'Ġthe', 'Ġcells', 'Ġhave', 'Ġglass', 'Ġfronts', 'Ġand', 'Ġface', 'Ġin', 'wards', ',', 'Ġso', 'Ġprivacy', 'Ġis', 'Ġnot', 'Ġhigh', 'Ġon', 'Ġthe', 'Ġagenda', '.', 'ĠEm', 'ĠCity', 'Ġis', 'Ġhome', 'Ġto', 'Ġmany', '..', 'A', 'ry', 'ans', ',', 'ĠMuslims', ',', 'Ġgang', 'st', 'as', ',', 'ĠLatinos', ',', 'ĠChristians', ',', 'ĠItalians', ',', 'ĠIrish', 'Ġand', 'Ġmore', '....', 'so', 'Ġsc', 'uff', 'les', ',', 'Ġdeath', 'Ġstares', ',', 'Ġdod', 'gy', 'Ġdealings', 'Ġand', 'Ġshady', 'Ġagreements', 'Ġare', 'Ġnever', 'Ġfar', 'Ġaway', '.<', 'br', 'Ġ/', '><', 'br', 'Ġ/>', 'I', 'Ġwould', 'Ġsay', 'Ġthe', 'Ġmain', 'Ġappeal', 'Ġof', 'Ġthe', 'Ġshow', 'Ġis', 'Ġdue', 'Ġto', 'Ġthe', 'Ġfact', 'Ġthat', 'Ġit', 'Ġgoes', 'Ġwhere', 'Ġother', 'Ġshows', 'Ġwouldn', \"'t\", 'Ġdare', '.', 'ĠForget', 'Ġpretty', 'Ġpictures', 'Ġpainted', 'Ġfor', 'Ġmainstream', 'Ġaudiences', ',', 'Ġforget', 'Ġcharm', ',', 'Ġforget', 'Ġromance', '...', 'O', 'Z', 'Ġdoesn', \"'t\", 'Ġmess', 'Ġaround', '.', 'ĠThe', 'Ġfirst', 'Ġepisode', 'ĠI', 'Ġever', 'Ġsaw', 'Ġstruck', 'Ġme', 'Ġas', 'Ġso', 'Ġnasty', 'Ġit', 'Ġwas', 'Ġsurreal', ',', 'ĠI', 'Ġcouldn', \"'t\", 'Ġsay', 'ĠI', 'Ġwas', 'Ġready', 'Ġfor', 'Ġit', ',', 'Ġbut', 'Ġas', 'ĠI', 'Ġwatched', 'Ġmore', ',', 'ĠI', 'Ġdeveloped', 'Ġa', 'Ġtaste', 'Ġfor', 'ĠOz', ',', 'Ġand', 'Ġgot', 'Ġaccustomed', 'Ġto', 'Ġthe', 'Ġhigh', 'Ġlevels', 'Ġof', 'Ġgraphic', 'Ġviolence', '.', 'ĠNot', 'Ġjust', 'Ġviolence', ',', 'Ġbut', 'Ġinjustice', 'Ġ(', 'cro', 'oked', 'Ġguards', 'Ġwho', \"'ll\", 'Ġbe', 'Ġsold', 'Ġout', 'Ġfor', 'Ġa', 'Ġnickel', ',', 'Ġinmates', 'Ġwho', \"'ll\", 'Ġkill', 'Ġon', 'Ġorder', 'Ġand', 'Ġget', 'Ġaway', 'Ġwith', 'Ġit', ',', 'Ġwell', 'Ġman', 'nered', ',', 'Ġmiddle', 'Ġclass', 'Ġinmates', 'Ġbeing', 'Ġturned', 'Ġinto', 'Ġprison', 'Ġbit', 'ches', 'Ġdue', 'Ġto', 'Ġtheir', 'Ġlack', 'Ġof', 'Ġstreet', 'Ġskills', 'Ġor', 'Ġprison', 'Ġexperience', ')', 'ĠWatching', 'ĠOz', ',', 'Ġyou', 'Ġmay', 'Ġbecome', 'Ġcomfortable', 'Ġwith', 'Ġwhat', 'Ġis', 'Ġuncomfortable', 'Ġviewing', '....', 'th', 'ats', 'Ġif', 'Ġyou', 'Ġcan', 'Ġget', 'Ġin', 'Ġtouch', 'Ġwith', 'Ġyour', 'Ġdarker', 'Ġside', '.']\n",
            "Token IDs:  [3762, 9, 5, 97, 34910, 34, 2801, 14, 71, 2494, 95, 112, 10548, 3238, 47, 581, 28, 18954, 4, 252, 32, 235, 6, 25, 42, 16, 2230, 99, 1102, 19, 162, 49069, 3809, 1589, 49007, 3809, 48709, 133, 78, 631, 14, 2322, 162, 59, 10548, 21, 63, 20509, 8, 29747, 3796, 154, 5422, 9, 1476, 6, 61, 278, 11, 235, 31, 5, 2136, 11932, 4, 3101, 162, 6, 42, 16, 45, 10, 311, 13, 5, 27922, 1144, 196, 50, 39649, 4, 152, 311, 16427, 117, 19594, 19, 11246, 7, 2196, 6, 2099, 50, 1476, 4, 3139, 16, 27482, 6, 11, 5, 4187, 304, 9, 5, 2136, 49069, 3809, 1589, 49007, 3809, 48709, 243, 16, 373, 384, 1301, 25, 14, 16, 5, 17911, 576, 7, 5, 35032, 35540, 2010, 331, 4676, 37403, 1766, 4, 85, 7235, 4412, 15, 28652, 412, 6, 41, 14073, 2810, 9, 5, 1789, 147, 70, 5, 4590, 33, 4049, 18958, 8, 652, 11, 17337, 6, 98, 4144, 16, 45, 239, 15, 5, 4026, 4, 3676, 412, 16, 184, 7, 171, 7586, 250, 1506, 1253, 6, 6299, 6, 5188, 620, 281, 6, 28514, 6, 9278, 6, 29481, 6, 3445, 8, 55, 17220, 2527, 2850, 5865, 1634, 6, 744, 40782, 6, 25744, 4740, 18380, 8, 31665, 5983, 32, 393, 444, 409, 49069, 3809, 1589, 49007, 3809, 48709, 100, 74, 224, 5, 1049, 2868, 9, 5, 311, 16, 528, 7, 5, 754, 14, 24, 1411, 147, 97, 924, 1979, 75, 19046, 4, 25449, 1256, 3493, 10122, 13, 7302, 7768, 6, 4309, 16426, 6, 4309, 9884, 734, 673, 1301, 630, 75, 7319, 198, 4, 20, 78, 3238, 38, 655, 794, 2322, 162, 25, 98, 15455, 24, 21, 19907, 6, 38, 1705, 75, 224, 38, 21, 1227, 13, 24, 6, 53, 25, 38, 3996, 55, 6, 38, 2226, 10, 5840, 13, 10548, 6, 8, 300, 21090, 7, 5, 239, 1389, 9, 11267, 1476, 4, 1491, 95, 1476, 6, 53, 16318, 36, 23324, 17477, 8528, 54, 581, 28, 1088, 66, 13, 10, 19500, 6, 8039, 54, 581, 3549, 15, 645, 8, 120, 409, 19, 24, 6, 157, 313, 30815, 6, 1692, 1380, 8039, 145, 1224, 88, 1789, 828, 5559, 528, 7, 49, 1762, 9, 2014, 2417, 50, 1789, 676, 43, 26535, 10548, 6, 47, 189, 555, 3473, 19, 99, 16, 9800, 7603, 17220, 212, 2923, 114, 47, 64, 120, 11, 2842, 19, 110, 20292, 526, 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for sent in tqdm(sentences):\n",
        "    encoded_dict = tokenizer.encode_plus(sent,add_special_tokens = True,max_length = 512,pad_to_max_length = True,\n",
        "                        return_attention_mask = True, return_tensors = 'pt',)\n",
        "    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "all_labels = torch.stack([label1], dim=1)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyJAOEQix40-",
        "outputId": "81bc9e6d-291f-43e7-c08d-252e2a2a3788"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/40000 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2310: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100%|██████████| 40000/40000 [00:34<00:00, 1149.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\n",
            "Token IDs: tensor([    0,  1711,    18,    59,     5,   129, 24670,   154,  1318,    11,\n",
            "           10,  1569,    14,  3680, 22536,     5, 18754,    18,  2316,    30,\n",
            "         2086,  1349,     9,    86,     6,  6197,     6,     8,  1219,    13,\n",
            "          145,  2622, 49069,  3809,  1589, 49007,  3809, 48709, 27576,     6,\n",
            "          141,    14,  2173,    19,     5, 11121,   655,   300,    10, 10196,\n",
            "           11,  3049,    16,  1684,   162,     4,     2,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = TensorDataset(input_ids, attention_masks, all_labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XqaL5G_x4rW",
        "outputId": "1da35f3a-bc08-47d4-8e98-00949e2e0bc2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36,000 training samples\n",
            "4,000 validation samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training on label 1"
      ],
      "metadata": {
        "id": "0wrGxMf6yFHd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "train_dataloader = DataLoader( train_dataset, shuffle=True, batch_size = batch_size)\n",
        "validation_dataloader = DataLoader( val_dataset, shuffle=False, batch_size = batch_size )\n",
        "\n",
        "\n",
        "model = RobertaForSequenceClassification.from_pretrained( \n",
        "    \"roberta-base\", num_labels = classes_number, output_attentions = False, output_hidden_states = False)\n",
        "\n",
        "model.cuda()"
      ],
      "metadata": {
        "id": "Kx29Kr9byEmV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "202286685d824e59abb841ca52aa74c5",
            "502f101cc8a24098b26b11e2b6fbfd00",
            "16cab721a3944034910b21679ff1cc06",
            "3fd783b454d04edf82780d57a7762ad1",
            "3e14bddc8b7847bb96521e61d8159580",
            "3e30590efae443da84a0677bdf3195e9",
            "23da1fb251b64a15b3f026f1e1011062",
            "f1fbf539137d4887b0a384ac7d58bff5",
            "d866695c3c9344a9ac250b43f89e1388",
            "699a4c16ade44646a02786f88bbeacbf",
            "cb3be4a608fa4c3aac58c9e1fde1e2b8"
          ]
        },
        "outputId": "b9b423e0-3f7c-496d-f3b0-9acf9f50e2ab"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/501M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "202286685d824e59abb841ca52aa74c5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaForSequenceClassification(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): RobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamW(model.parameters(), lr = 2e-5, eps = 1e-8 )\n",
        "\n",
        "epochs = 4\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = total_steps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umd9G6H8yLmd",
        "outputId": "34869df7-1486-4ee8-a7b6-7b7869bd2cae"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def flat_accuracy(preds1,labels):\n",
        "    pred_flat1 = np.argmax(preds1, axis=1).flatten()\n",
        "    labels = labels.flatten() \n",
        "    labels_flat1=np.asarray(labels)\n",
        "    acc1= np.sum(pred_flat1 == labels_flat1) / len(labels_flat1)\n",
        "    #return (acc1+acc2)/2\n",
        "    return acc1"
      ],
      "metadata": {
        "id": "yewC5MrPyNwE"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "metadata": {
        "id": "LLr9N5nhyPci"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    # Perform one full pass over the training set.\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # print(b_labels.shape)\n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "        result = model(b_input_ids, \n",
        "                       token_type_ids=None, \n",
        "                       attention_mask=b_input_mask, \n",
        "                       return_dict=True)\n",
        "        label1_preds = result[\"logits\"][:, :6]\n",
        "        label1_loss = torch.nn.functional.cross_entropy(label1_preds, b_labels[:, 0])\n",
        "\n",
        "\n",
        "        loss = label1_loss\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    total_eval_accuracy1 = 0\n",
        "    total_eval_accuracy2 = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        with torch.no_grad():        \n",
        "\n",
        "            result = model(b_input_ids, \n",
        "                           token_type_ids=None, \n",
        "                           attention_mask=b_input_mask,\n",
        "                           return_dict=True)\n",
        "\n",
        "        label1_preds = result[\"logits\"][:, :label_1_num_classes]\n",
        "        label1_loss = torch.nn.functional.cross_entropy(label1_preds, b_labels[:, 0])\n",
        "\n",
        "\n",
        "        loss = label1_loss \n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        label1_preds = label1_preds.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        eval_1 = flat_accuracy(label1_preds,label_ids)\n",
        "        total_eval_accuracy1+=eval_1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy1 = total_eval_accuracy1 / len(validation_dataloader)\n",
        "    print(\"  Accuracy1: {0:.2f}\".format(avg_val_accuracy1))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur. Label1.': avg_val_accuracy1,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        " \n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "388lbJ0xyPTQ",
        "outputId": "78703839-51af-49b4-959c-4907d4c396fb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  1,125.    Elapsed: 0:00:31.\n",
            "  Batch    80  of  1,125.    Elapsed: 0:00:59.\n",
            "  Batch   120  of  1,125.    Elapsed: 0:01:27.\n",
            "  Batch   160  of  1,125.    Elapsed: 0:01:55.\n",
            "  Batch   200  of  1,125.    Elapsed: 0:02:24.\n",
            "  Batch   240  of  1,125.    Elapsed: 0:02:52.\n",
            "  Batch   280  of  1,125.    Elapsed: 0:03:20.\n",
            "  Batch   320  of  1,125.    Elapsed: 0:03:48.\n",
            "  Batch   360  of  1,125.    Elapsed: 0:04:16.\n",
            "  Batch   400  of  1,125.    Elapsed: 0:04:44.\n",
            "  Batch   440  of  1,125.    Elapsed: 0:05:13.\n",
            "  Batch   480  of  1,125.    Elapsed: 0:05:41.\n",
            "  Batch   520  of  1,125.    Elapsed: 0:06:09.\n",
            "  Batch   560  of  1,125.    Elapsed: 0:06:37.\n",
            "  Batch   600  of  1,125.    Elapsed: 0:07:05.\n",
            "  Batch   640  of  1,125.    Elapsed: 0:07:33.\n",
            "  Batch   680  of  1,125.    Elapsed: 0:08:02.\n",
            "  Batch   720  of  1,125.    Elapsed: 0:08:30.\n",
            "  Batch   760  of  1,125.    Elapsed: 0:08:58.\n",
            "  Batch   800  of  1,125.    Elapsed: 0:09:26.\n",
            "  Batch   840  of  1,125.    Elapsed: 0:09:54.\n",
            "  Batch   880  of  1,125.    Elapsed: 0:10:23.\n",
            "  Batch   920  of  1,125.    Elapsed: 0:10:51.\n",
            "  Batch   960  of  1,125.    Elapsed: 0:11:19.\n",
            "  Batch 1,000  of  1,125.    Elapsed: 0:11:47.\n",
            "  Batch 1,040  of  1,125.    Elapsed: 0:12:15.\n",
            "  Batch 1,080  of  1,125.    Elapsed: 0:12:43.\n",
            "  Batch 1,120  of  1,125.    Elapsed: 0:13:12.\n",
            "\n",
            "  Average training loss: 0.20\n",
            "  Training epcoh took: 0:13:15\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy1: 0.94\n",
            "  Validation Loss: 0.15\n",
            "  Validation took: 0:00:28\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  1,125.    Elapsed: 0:00:28.\n",
            "  Batch    80  of  1,125.    Elapsed: 0:00:56.\n",
            "  Batch   120  of  1,125.    Elapsed: 0:01:24.\n",
            "  Batch   160  of  1,125.    Elapsed: 0:01:53.\n",
            "  Batch   200  of  1,125.    Elapsed: 0:02:21.\n",
            "  Batch   240  of  1,125.    Elapsed: 0:02:49.\n",
            "  Batch   280  of  1,125.    Elapsed: 0:03:17.\n",
            "  Batch   320  of  1,125.    Elapsed: 0:03:45.\n",
            "  Batch   360  of  1,125.    Elapsed: 0:04:13.\n",
            "  Batch   400  of  1,125.    Elapsed: 0:04:42.\n",
            "  Batch   440  of  1,125.    Elapsed: 0:05:10.\n",
            "  Batch   480  of  1,125.    Elapsed: 0:05:38.\n",
            "  Batch   520  of  1,125.    Elapsed: 0:06:06.\n",
            "  Batch   560  of  1,125.    Elapsed: 0:06:34.\n",
            "  Batch   600  of  1,125.    Elapsed: 0:07:03.\n",
            "  Batch   640  of  1,125.    Elapsed: 0:07:31.\n",
            "  Batch   680  of  1,125.    Elapsed: 0:07:59.\n",
            "  Batch   720  of  1,125.    Elapsed: 0:08:27.\n",
            "  Batch   760  of  1,125.    Elapsed: 0:08:55.\n",
            "  Batch   800  of  1,125.    Elapsed: 0:09:23.\n",
            "  Batch   840  of  1,125.    Elapsed: 0:09:52.\n",
            "  Batch   880  of  1,125.    Elapsed: 0:10:20.\n",
            "  Batch   920  of  1,125.    Elapsed: 0:10:48.\n",
            "  Batch   960  of  1,125.    Elapsed: 0:11:16.\n",
            "  Batch 1,000  of  1,125.    Elapsed: 0:11:44.\n",
            "  Batch 1,040  of  1,125.    Elapsed: 0:12:12.\n",
            "  Batch 1,080  of  1,125.    Elapsed: 0:12:41.\n",
            "  Batch 1,120  of  1,125.    Elapsed: 0:13:09.\n",
            "\n",
            "  Average training loss: 0.11\n",
            "  Training epcoh took: 0:13:12\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy1: 0.95\n",
            "  Validation Loss: 0.18\n",
            "  Validation took: 0:00:28\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  1,125.    Elapsed: 0:00:28.\n",
            "  Batch    80  of  1,125.    Elapsed: 0:00:56.\n",
            "  Batch   120  of  1,125.    Elapsed: 0:01:25.\n",
            "  Batch   160  of  1,125.    Elapsed: 0:01:53.\n",
            "  Batch   200  of  1,125.    Elapsed: 0:02:21.\n",
            "  Batch   240  of  1,125.    Elapsed: 0:02:49.\n",
            "  Batch   280  of  1,125.    Elapsed: 0:03:17.\n",
            "  Batch   320  of  1,125.    Elapsed: 0:03:45.\n",
            "  Batch   360  of  1,125.    Elapsed: 0:04:14.\n",
            "  Batch   400  of  1,125.    Elapsed: 0:04:42.\n",
            "  Batch   440  of  1,125.    Elapsed: 0:05:10.\n",
            "  Batch   480  of  1,125.    Elapsed: 0:05:38.\n",
            "  Batch   520  of  1,125.    Elapsed: 0:06:06.\n",
            "  Batch   560  of  1,125.    Elapsed: 0:06:34.\n",
            "  Batch   600  of  1,125.    Elapsed: 0:07:03.\n",
            "  Batch   640  of  1,125.    Elapsed: 0:07:31.\n",
            "  Batch   680  of  1,125.    Elapsed: 0:07:59.\n",
            "  Batch   720  of  1,125.    Elapsed: 0:08:27.\n",
            "  Batch   760  of  1,125.    Elapsed: 0:08:55.\n",
            "  Batch   800  of  1,125.    Elapsed: 0:09:23.\n",
            "  Batch   840  of  1,125.    Elapsed: 0:09:51.\n",
            "  Batch   880  of  1,125.    Elapsed: 0:10:20.\n",
            "  Batch   920  of  1,125.    Elapsed: 0:10:48.\n",
            "  Batch   960  of  1,125.    Elapsed: 0:11:16.\n",
            "  Batch 1,000  of  1,125.    Elapsed: 0:11:44.\n",
            "  Batch 1,040  of  1,125.    Elapsed: 0:12:12.\n",
            "  Batch 1,080  of  1,125.    Elapsed: 0:12:41.\n",
            "  Batch 1,120  of  1,125.    Elapsed: 0:13:09.\n",
            "\n",
            "  Average training loss: 0.07\n",
            "  Training epcoh took: 0:13:12\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy1: 0.95\n",
            "  Validation Loss: 0.20\n",
            "  Validation took: 0:00:28\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  1,125.    Elapsed: 0:00:28.\n",
            "  Batch    80  of  1,125.    Elapsed: 0:00:56.\n",
            "  Batch   120  of  1,125.    Elapsed: 0:01:24.\n",
            "  Batch   160  of  1,125.    Elapsed: 0:01:53.\n",
            "  Batch   200  of  1,125.    Elapsed: 0:02:21.\n",
            "  Batch   240  of  1,125.    Elapsed: 0:02:49.\n",
            "  Batch   280  of  1,125.    Elapsed: 0:03:17.\n",
            "  Batch   320  of  1,125.    Elapsed: 0:03:45.\n",
            "  Batch   360  of  1,125.    Elapsed: 0:04:13.\n",
            "  Batch   400  of  1,125.    Elapsed: 0:04:42.\n",
            "  Batch   440  of  1,125.    Elapsed: 0:05:10.\n",
            "  Batch   480  of  1,125.    Elapsed: 0:05:38.\n",
            "  Batch   520  of  1,125.    Elapsed: 0:06:06.\n",
            "  Batch   560  of  1,125.    Elapsed: 0:06:34.\n",
            "  Batch   600  of  1,125.    Elapsed: 0:07:02.\n",
            "  Batch   640  of  1,125.    Elapsed: 0:07:31.\n",
            "  Batch   680  of  1,125.    Elapsed: 0:07:59.\n",
            "  Batch   720  of  1,125.    Elapsed: 0:08:27.\n",
            "  Batch   760  of  1,125.    Elapsed: 0:08:55.\n",
            "  Batch   800  of  1,125.    Elapsed: 0:09:23.\n",
            "  Batch   840  of  1,125.    Elapsed: 0:09:51.\n",
            "  Batch   880  of  1,125.    Elapsed: 0:10:20.\n",
            "  Batch   920  of  1,125.    Elapsed: 0:10:48.\n",
            "  Batch   960  of  1,125.    Elapsed: 0:11:16.\n",
            "  Batch 1,000  of  1,125.    Elapsed: 0:11:44.\n",
            "  Batch 1,040  of  1,125.    Elapsed: 0:12:12.\n",
            "  Batch 1,080  of  1,125.    Elapsed: 0:12:40.\n",
            "  Batch 1,120  of  1,125.    Elapsed: 0:13:09.\n",
            "\n",
            "  Average training loss: 0.04\n",
            "  Training epcoh took: 0:13:12\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy1: 0.95\n",
            "  Validation Loss: 0.22\n",
            "  Validation took: 0:00:28\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:54:44 (h:mm:ss)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculating testing accuracy."
      ],
      "metadata": {
        "id": "Qmt6gOJM1Tir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data={'sentence':X_test,'label':y_test}\n",
        "df=pd.DataFrame(data, columns =['label','sentence']) \n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values\n",
        "\n",
        "label_1_num_classes = classes_number\n",
        "\n",
        "# from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# label1_encoder = LabelEncoder()\n",
        "\n",
        "# label1 = [item[0] for item in labels]\n",
        "# label1 = label1_encoder.fit_transform(label1)\n",
        "\n",
        "label1 = torch.LongTensor(labels)\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for sent in sentences:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                sent,add_special_tokens = True,max_length = 512,pad_to_max_length = True, return_attention_mask = True,return_tensors = 'pt',)\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "all_labels = torch.stack([label1], dim=1)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, all_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, shuffle=False, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "_-15jhi61KOL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7640b662-76c1-4354-f8e5-665555307b3d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of test sentences: 10,000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction on test set\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "prediction_list = []\n",
        "real_list=[]\n",
        "accuracy1 = 0\n",
        "total_count = 0\n",
        "misclassify1=0\n",
        "misclassify_data=[]\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict\n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions.\n",
        "      result = model(b_input_ids, \n",
        "                     token_type_ids=None, \n",
        "                     attention_mask=b_input_mask,\n",
        "                     return_dict=True)\n",
        "\n",
        "  #logits = result.logits\n",
        "  label1_preds = result[\"logits\"][:, :label_1_num_classes]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  label1_preds = label1_preds.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "  label1_preds=np.argmax(label1_preds,axis=1)\n",
        "  label_ids = label_ids.flatten()\n",
        "\n",
        "  for i in range(len(label_ids)):\n",
        "    prediction_list.append(label1_preds[i])\n",
        "    real_list.append(label_ids[i])\n",
        "    if(label1_preds[i]==label_ids[i]):\n",
        "      accuracy1+=1\n",
        "    else:\n",
        "      misclassify1+=1\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print(\"Number of Label1 correctly predicted: \"+str(accuracy1))\n",
        "print(\"Number of Label1 misclassify: \"+str(misclassify1))\n",
        "\n",
        "print(\"Label1 Testing Accuracy: {:.2f}\".format(accuracy1/(accuracy1+misclassify1) ) )\n",
        "bert_singlelabel_accuracy1 = accuracy1/(accuracy1+misclassify1)"
      ],
      "metadata": {
        "id": "U9RkqHLt1ZBe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b1d71eb-4478-40c3-b271-2d13e558387d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels for 10,000 test sentences...\n",
            "\n",
            "Number of Label1 correctly predicted: 9568\n",
            "Number of Label1 misclassify: 432\n",
            "Label1 Testing Accuracy: 0.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "sns.heatmap(confusion_matrix(real_list,prediction_list), annot=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "1-LGRUcagaEG",
        "outputId": "c2b46c83-0601-4d94-9384-3ef76e1e57d4"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb975150950>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}