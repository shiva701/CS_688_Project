{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e18e509f6f61491bbdd23d5594766df6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ed7ffd4b7b4a45998715b4410ae12815",
              "IPY_MODEL_0883e1d6bf684ba6a188f7f68c0e4ce6",
              "IPY_MODEL_a44a6e473ed744b49c0c37beae4eb9cd"
            ],
            "layout": "IPY_MODEL_5eb4497cad734a77aafd77c76a0a2048"
          }
        },
        "ed7ffd4b7b4a45998715b4410ae12815": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_303094d40e494931ae94b6bbde8e2842",
            "placeholder": "​",
            "style": "IPY_MODEL_e8b016c943684d61981c9bc28708f5b3",
            "value": "Downloading: 100%"
          }
        },
        "0883e1d6bf684ba6a188f7f68c0e4ce6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90549bf6b7254add8f0ecf726184933b",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5712dd68125046a0bbc2d5a9fb27b2b4",
            "value": 231508
          }
        },
        "a44a6e473ed744b49c0c37beae4eb9cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50278abd4b4547dd85507dd62306ec63",
            "placeholder": "​",
            "style": "IPY_MODEL_a7635a325b7b4557a95efa203d261e98",
            "value": " 232k/232k [00:00&lt;00:00, 1.64MB/s]"
          }
        },
        "5eb4497cad734a77aafd77c76a0a2048": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "303094d40e494931ae94b6bbde8e2842": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8b016c943684d61981c9bc28708f5b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90549bf6b7254add8f0ecf726184933b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5712dd68125046a0bbc2d5a9fb27b2b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "50278abd4b4547dd85507dd62306ec63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7635a325b7b4557a95efa203d261e98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "331e784bbd3d4e7e8b59091b609ac3f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_72a212cb448b434bb85cb7bff983a794",
              "IPY_MODEL_6f3087711bb04757a073c0f4d70255ae",
              "IPY_MODEL_884644c09b2545d487fe97b07e90f514"
            ],
            "layout": "IPY_MODEL_762f0828521e4d7283fc257f8c1a24f3"
          }
        },
        "72a212cb448b434bb85cb7bff983a794": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32a92176ca9d41aca4d04833a58317c0",
            "placeholder": "​",
            "style": "IPY_MODEL_5be1fe9f8fa64dd5b3454296e8a28b1e",
            "value": "Downloading: 100%"
          }
        },
        "6f3087711bb04757a073c0f4d70255ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e90f0b066edf4cd2b4c626b801880421",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8f3d663bc6554df89447252ccc68ee5e",
            "value": 28
          }
        },
        "884644c09b2545d487fe97b07e90f514": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b639a6ca678437fa1c3b3add1ab0bbf",
            "placeholder": "​",
            "style": "IPY_MODEL_f54e6d7e4ebb4607a1872f7e893eb28a",
            "value": " 28.0/28.0 [00:00&lt;00:00, 1.05kB/s]"
          }
        },
        "762f0828521e4d7283fc257f8c1a24f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32a92176ca9d41aca4d04833a58317c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5be1fe9f8fa64dd5b3454296e8a28b1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e90f0b066edf4cd2b4c626b801880421": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f3d663bc6554df89447252ccc68ee5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4b639a6ca678437fa1c3b3add1ab0bbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f54e6d7e4ebb4607a1872f7e893eb28a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f9de5feed5e409aa7b2363db5151787": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a43780edecb14cb083abeede9cd5928a",
              "IPY_MODEL_805b7e873d884391aa69c7451f5a1ff4",
              "IPY_MODEL_42aa9e2992384d61873f37d93cc8f663"
            ],
            "layout": "IPY_MODEL_4c0095ab9c6243bc9358ad8b084dc5dc"
          }
        },
        "a43780edecb14cb083abeede9cd5928a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_614d2abf9c624e6ca5d3c7d210b71329",
            "placeholder": "​",
            "style": "IPY_MODEL_5d4921247cdb47078fab3f7bbb5a8421",
            "value": "Downloading: 100%"
          }
        },
        "805b7e873d884391aa69c7451f5a1ff4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3039ac49f761474fb2915ed1dd26d186",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ecca1deeaba746aea4625a3115fa3be0",
            "value": 570
          }
        },
        "42aa9e2992384d61873f37d93cc8f663": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99c5777d7e944e53be7174e81fb24fde",
            "placeholder": "​",
            "style": "IPY_MODEL_9cab79483061448697e80b76711b49cf",
            "value": " 570/570 [00:00&lt;00:00, 22.5kB/s]"
          }
        },
        "4c0095ab9c6243bc9358ad8b084dc5dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "614d2abf9c624e6ca5d3c7d210b71329": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d4921247cdb47078fab3f7bbb5a8421": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3039ac49f761474fb2915ed1dd26d186": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecca1deeaba746aea4625a3115fa3be0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "99c5777d7e944e53be7174e81fb24fde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cab79483061448697e80b76711b49cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "019b63bd733f469b9ac0b54080b8d2af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_18f086a5619d4cf0b17a50ebcf5bd199",
              "IPY_MODEL_a6a23ed51aad41f1a5187b1a9abe7ecf",
              "IPY_MODEL_54e3bfb46e3b42ecbc716652f9b1ed1a"
            ],
            "layout": "IPY_MODEL_e95fec3979f449f886bb64e9151b18b6"
          }
        },
        "18f086a5619d4cf0b17a50ebcf5bd199": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5c72932e5cd4216b9cee730d74de977",
            "placeholder": "​",
            "style": "IPY_MODEL_b9d69cf021f641ada107f37ce95da1d7",
            "value": "Downloading: 100%"
          }
        },
        "a6a23ed51aad41f1a5187b1a9abe7ecf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cda45d0d32424f04a8c276c09b760d36",
            "max": 440473133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0a3bb70bf723443c83b147ef60a3b193",
            "value": 440473133
          }
        },
        "54e3bfb46e3b42ecbc716652f9b1ed1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_166a1dd4a14b47eb910f435842a63f0d",
            "placeholder": "​",
            "style": "IPY_MODEL_a90eabb3beb845b7b58850f7b2d370f8",
            "value": " 440M/440M [00:07&lt;00:00, 62.1MB/s]"
          }
        },
        "e95fec3979f449f886bb64e9151b18b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5c72932e5cd4216b9cee730d74de977": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9d69cf021f641ada107f37ce95da1d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cda45d0d32424f04a8c276c09b760d36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a3bb70bf723443c83b147ef60a3b193": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "166a1dd4a14b47eb910f435842a63f0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a90eabb3beb845b7b58850f7b2d370f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Loading Data"
      ],
      "metadata": {
        "id": "T_tfnIWPC0mF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rx-xRH9IuK87",
        "outputId": "3997eea4-7ade-4b43-86ee-3b35b5d6988b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/CS-688_Project/IMDB/IMDB Dataset.csv\")"
      ],
      "metadata": {
        "id": "cHpohSmgwLjP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data=(data.iloc[:100,:])"
      ],
      "metadata": {
        "id": "Rpi5rlNv0wzp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Libraries"
      ],
      "metadata": {
        "id": "K9yiifL5wZ4C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Doing some experimentations I notice that there was a CUDA error coming with older version of PyTorch, so it's advisable to upgrade PyTorch version."
      ],
      "metadata": {
        "id": "W0-gsmwhwZ4E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade torch"
      ],
      "metadata": {
        "id": "lzehLcpzwZ4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9c7b4ba-b621-4d84-b19b-6cb6d9a294c1",
        "id": "MbNgyDqzwZ4G"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5 MB 4.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 80.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 88.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.10.1 tokenizers-0.13.2 transformers-4.24.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import random\n",
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig"
      ],
      "metadata": {
        "id": "RdLBxD98wZ4H"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4797d3cc-c8e7-4fb4-f335-082f15d6a5eb",
        "id": "i06kd8rvwZ4I"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: A100-SXM4-40GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Processing Data"
      ],
      "metadata": {
        "id": "zCRhKOoNwgte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=data"
      ],
      "metadata": {
        "id": "LYW46GUXurbB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = df['review'].tolist()\n",
        "label1 = df['sentiment'].tolist()\n",
        "\n",
        "c = Counter(label1)\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "Intent = []\n",
        "Occurance = []\n",
        "for i in c.items():\n",
        "  Intent.append(i[0])\n",
        "  Occurance.append(i[1])\n",
        "ax.bar(Intent,Occurance,color=(0.2, 0.4, 0.6, 0.6))  \n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "3fbb3083-3f8e-4470-b0df-e3627aafd0fe",
        "id": "vIrByRkgwgth"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {
        "id": "_MkV9gziw8-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dic={'positive':0,'negative':1}\n",
        "ans={0:'positive',1:'negative'}\n",
        "\n",
        "classes_number = len(dic)\n",
        "\n",
        "print(\"classes_number:\",classes_number)"
      ],
      "metadata": {
        "id": "2MOfbnVZN-yh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e61df78c-6d97-4db2-8751-6759832b9e0b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classes_number: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels=data['sentiment']\n",
        "sentence=data['review']\n",
        "\n",
        "for i in range(len(labels)):\n",
        "  labels[i]=dic[labels[i]]"
      ],
      "metadata": {
        "id": "FAnL8ekpu9Cj"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(label1)):\n",
        " label1[i]=dic[label1[i]]\n",
        "\n",
        "data={'sentence':sentence,'label1':labels}\n",
        "df=pd.DataFrame(data)\n",
        "print(len(df))\n",
        "df=df.drop_duplicates()\n",
        "print(len(df))"
      ],
      "metadata": {
        "id": "0kzB-cbMOyVJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b06dc1e-a12b-4bde-80ae-c0b1b29f7c5f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50000\n",
            "49582\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(sentence, label1, test_size = 0.20, random_state = 0)"
      ],
      "metadata": {
        "id": "v_uwuxrGwSkj"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = X_train\n",
        "labels = y_train"
      ],
      "metadata": {
        "id": "qs928X_GwSjJ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_1_num_classes = classes_number\n",
        "\n",
        "label1 = torch.LongTensor(labels)"
      ],
      "metadata": {
        "id": "IkUNRhFIwciE"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading BERT Model and Creating Data Frame"
      ],
      "metadata": {
        "id": "bDawdeDgxy-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202,
          "referenced_widgets": [
            "e18e509f6f61491bbdd23d5594766df6",
            "ed7ffd4b7b4a45998715b4410ae12815",
            "0883e1d6bf684ba6a188f7f68c0e4ce6",
            "a44a6e473ed744b49c0c37beae4eb9cd",
            "5eb4497cad734a77aafd77c76a0a2048",
            "303094d40e494931ae94b6bbde8e2842",
            "e8b016c943684d61981c9bc28708f5b3",
            "90549bf6b7254add8f0ecf726184933b",
            "5712dd68125046a0bbc2d5a9fb27b2b4",
            "50278abd4b4547dd85507dd62306ec63",
            "a7635a325b7b4557a95efa203d261e98",
            "331e784bbd3d4e7e8b59091b609ac3f3",
            "72a212cb448b434bb85cb7bff983a794",
            "6f3087711bb04757a073c0f4d70255ae",
            "884644c09b2545d487fe97b07e90f514",
            "762f0828521e4d7283fc257f8c1a24f3",
            "32a92176ca9d41aca4d04833a58317c0",
            "5be1fe9f8fa64dd5b3454296e8a28b1e",
            "e90f0b066edf4cd2b4c626b801880421",
            "8f3d663bc6554df89447252ccc68ee5e",
            "4b639a6ca678437fa1c3b3add1ab0bbf",
            "f54e6d7e4ebb4607a1872f7e893eb28a",
            "2f9de5feed5e409aa7b2363db5151787",
            "a43780edecb14cb083abeede9cd5928a",
            "805b7e873d884391aa69c7451f5a1ff4",
            "42aa9e2992384d61873f37d93cc8f663",
            "4c0095ab9c6243bc9358ad8b084dc5dc",
            "614d2abf9c624e6ca5d3c7d210b71329",
            "5d4921247cdb47078fab3f7bbb5a8421",
            "3039ac49f761474fb2915ed1dd26d186",
            "ecca1deeaba746aea4625a3115fa3be0",
            "99c5777d7e944e53be7174e81fb24fde",
            "9cab79483061448697e80b76711b49cf"
          ]
        },
        "id": "iDsAxHLAxwUX",
        "outputId": "586e7fe1-d091-42af-94b0-1b7ded7b8803"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e18e509f6f61491bbdd23d5594766df6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "331e784bbd3d4e7e8b59091b609ac3f3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f9de5feed5e409aa7b2363db5151787"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Original:  One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\n",
            "Tokenized:  ['one', 'of', 'the', 'other', 'reviewers', 'has', 'mentioned', 'that', 'after', 'watching', 'just', '1', 'oz', 'episode', 'you', \"'\", 'll', 'be', 'hooked', '.', 'they', 'are', 'right', ',', 'as', 'this', 'is', 'exactly', 'what', 'happened', 'with', 'me', '.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'the', 'first', 'thing', 'that', 'struck', 'me', 'about', 'oz', 'was', 'its', 'brutality', 'and', 'un', '##fl', '##in', '##ching', 'scenes', 'of', 'violence', ',', 'which', 'set', 'in', 'right', 'from', 'the', 'word', 'go', '.', 'trust', 'me', ',', 'this', 'is', 'not', 'a', 'show', 'for', 'the', 'faint', 'hearted', 'or', 'tim', '##id', '.', 'this', 'show', 'pulls', 'no', 'punches', 'with', 'regards', 'to', 'drugs', ',', 'sex', 'or', 'violence', '.', 'its', 'is', 'hardcore', ',', 'in', 'the', 'classic', 'use', 'of', 'the', 'word', '.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'it', 'is', 'called', 'oz', 'as', 'that', 'is', 'the', 'nickname', 'given', 'to', 'the', 'oswald', 'maximum', 'security', 'state', 'pen', '##ite', '##nta', '##ry', '.', 'it', 'focuses', 'mainly', 'on', 'emerald', 'city', ',', 'an', 'experimental', 'section', 'of', 'the', 'prison', 'where', 'all', 'the', 'cells', 'have', 'glass', 'fronts', 'and', 'face', 'inward', '##s', ',', 'so', 'privacy', 'is', 'not', 'high', 'on', 'the', 'agenda', '.', 'em', 'city', 'is', 'home', 'to', 'many', '.', '.', 'aryan', '##s', ',', 'muslims', ',', 'gangs', '##tas', ',', 'latino', '##s', ',', 'christians', ',', 'italians', ',', 'irish', 'and', 'more', '.', '.', '.', '.', 'so', 'sc', '##uf', '##fles', ',', 'death', 'stares', ',', 'dod', '##gy', 'dealings', 'and', 'shady', 'agreements', 'are', 'never', 'far', 'away', '.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'i', 'would', 'say', 'the', 'main', 'appeal', 'of', 'the', 'show', 'is', 'due', 'to', 'the', 'fact', 'that', 'it', 'goes', 'where', 'other', 'shows', 'wouldn', \"'\", 't', 'dare', '.', 'forget', 'pretty', 'pictures', 'painted', 'for', 'mainstream', 'audiences', ',', 'forget', 'charm', ',', 'forget', 'romance', '.', '.', '.', 'oz', 'doesn', \"'\", 't', 'mess', 'around', '.', 'the', 'first', 'episode', 'i', 'ever', 'saw', 'struck', 'me', 'as', 'so', 'nasty', 'it', 'was', 'surreal', ',', 'i', 'couldn', \"'\", 't', 'say', 'i', 'was', 'ready', 'for', 'it', ',', 'but', 'as', 'i', 'watched', 'more', ',', 'i', 'developed', 'a', 'taste', 'for', 'oz', ',', 'and', 'got', 'accustomed', 'to', 'the', 'high', 'levels', 'of', 'graphic', 'violence', '.', 'not', 'just', 'violence', ',', 'but', 'injustice', '(', 'crooked', 'guards', 'who', \"'\", 'll', 'be', 'sold', 'out', 'for', 'a', 'nickel', ',', 'inmates', 'who', \"'\", 'll', 'kill', 'on', 'order', 'and', 'get', 'away', 'with', 'it', ',', 'well', 'manner', '##ed', ',', 'middle', 'class', 'inmates', 'being', 'turned', 'into', 'prison', 'bitch', '##es', 'due', 'to', 'their', 'lack', 'of', 'street', 'skills', 'or', 'prison', 'experience', ')', 'watching', 'oz', ',', 'you', 'may', 'become', 'comfortable', 'with', 'what', 'is', 'uncomfortable', 'viewing', '.', '.', '.', '.', 'that', '##s', 'if', 'you', 'can', 'get', 'in', 'touch', 'with', 'your', 'darker', 'side', '.']\n",
            "Token IDs:  [2028, 1997, 1996, 2060, 15814, 2038, 3855, 2008, 2044, 3666, 2074, 1015, 11472, 2792, 2017, 1005, 2222, 2022, 13322, 1012, 2027, 2024, 2157, 1010, 2004, 2023, 2003, 3599, 2054, 3047, 2007, 2033, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1996, 2034, 2518, 2008, 4930, 2033, 2055, 11472, 2001, 2049, 24083, 1998, 4895, 10258, 2378, 8450, 5019, 1997, 4808, 1010, 2029, 2275, 1999, 2157, 2013, 1996, 2773, 2175, 1012, 3404, 2033, 1010, 2023, 2003, 2025, 1037, 2265, 2005, 1996, 8143, 18627, 2030, 5199, 3593, 1012, 2023, 2265, 8005, 2053, 17957, 2007, 12362, 2000, 5850, 1010, 3348, 2030, 4808, 1012, 2049, 2003, 13076, 1010, 1999, 1996, 4438, 2224, 1997, 1996, 2773, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2009, 2003, 2170, 11472, 2004, 2008, 2003, 1996, 8367, 2445, 2000, 1996, 17411, 4555, 3036, 2110, 7279, 4221, 12380, 2854, 1012, 2009, 7679, 3701, 2006, 14110, 2103, 1010, 2019, 6388, 2930, 1997, 1996, 3827, 2073, 2035, 1996, 4442, 2031, 3221, 21430, 1998, 2227, 20546, 2015, 1010, 2061, 9394, 2003, 2025, 2152, 2006, 1996, 11376, 1012, 7861, 2103, 2003, 2188, 2000, 2116, 1012, 1012, 26030, 2015, 1010, 7486, 1010, 18542, 10230, 1010, 7402, 2015, 1010, 8135, 1010, 16773, 1010, 3493, 1998, 2062, 1012, 1012, 1012, 1012, 2061, 8040, 16093, 28331, 1010, 2331, 14020, 1010, 26489, 6292, 24069, 1998, 22824, 10540, 2024, 2196, 2521, 2185, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1045, 2052, 2360, 1996, 2364, 5574, 1997, 1996, 2265, 2003, 2349, 2000, 1996, 2755, 2008, 2009, 3632, 2073, 2060, 3065, 2876, 1005, 1056, 8108, 1012, 5293, 3492, 4620, 4993, 2005, 7731, 9501, 1010, 5293, 11084, 1010, 5293, 7472, 1012, 1012, 1012, 11472, 2987, 1005, 1056, 6752, 2105, 1012, 1996, 2034, 2792, 1045, 2412, 2387, 4930, 2033, 2004, 2061, 11808, 2009, 2001, 16524, 1010, 1045, 2481, 1005, 1056, 2360, 1045, 2001, 3201, 2005, 2009, 1010, 2021, 2004, 1045, 3427, 2062, 1010, 1045, 2764, 1037, 5510, 2005, 11472, 1010, 1998, 2288, 17730, 2000, 1996, 2152, 3798, 1997, 8425, 4808, 1012, 2025, 2074, 4808, 1010, 2021, 21321, 1006, 15274, 4932, 2040, 1005, 2222, 2022, 2853, 2041, 2005, 1037, 15519, 1010, 13187, 2040, 1005, 2222, 3102, 2006, 2344, 1998, 2131, 2185, 2007, 2009, 1010, 2092, 5450, 2098, 1010, 2690, 2465, 13187, 2108, 2357, 2046, 3827, 7743, 2229, 2349, 2000, 2037, 3768, 1997, 2395, 4813, 2030, 3827, 3325, 1007, 3666, 11472, 1010, 2017, 2089, 2468, 6625, 2007, 2054, 2003, 8796, 10523, 1012, 1012, 1012, 1012, 2008, 2015, 2065, 2017, 2064, 2131, 1999, 3543, 2007, 2115, 9904, 2217, 1012]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "4hNPQKN48Q4o"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for sent in tqdm(sentences):\n",
        "    encoded_dict = tokenizer.encode_plus(sent,add_special_tokens = True,max_length = 512,pad_to_max_length = True,\n",
        "                        return_attention_mask = True, return_tensors = 'pt',)\n",
        "    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "all_labels = torch.stack([label1], dim=1)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyJAOEQix40-",
        "outputId": "e0738b3c-5505-435a-b36f-7799f55c69ab"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/40000 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2310: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100%|██████████| 40000/40000 [03:58<00:00, 167.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\n",
            "Token IDs: tensor([  101,  2008,  1005,  1055,  2055,  1996,  2069,  2417, 21564,  2075,\n",
            "         3737,  1999,  1037,  3185,  2008,  4728, 23862,  1996, 13972,  1005,\n",
            "         1055,  4454,  2011,  3974,  2650,  1997,  2051,  1010,  5436,  1010,\n",
            "         1998,  3114,  2005,  2108,  2550,  1012,  1026,  7987,  1013,  1028,\n",
            "         1026,  7987,  1013,  1028,  4606,  1010,  2129,  2008,  3124,  2007,\n",
            "         1996,  7877,  2412,  2288,  1037, 15453,  1999,  5365,  2003,  3458,\n",
            "         2033,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = TensorDataset(input_ids, attention_masks, all_labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XqaL5G_x4rW",
        "outputId": "91467585-ccf7-4d4a-c213-ba4db1749965"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36,000 training samples\n",
            "4,000 validation samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training on label 1"
      ],
      "metadata": {
        "id": "0wrGxMf6yFHd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "train_dataloader = DataLoader( train_dataset, shuffle=True, batch_size = batch_size)\n",
        "validation_dataloader = DataLoader( val_dataset, shuffle=False, batch_size = batch_size )\n",
        "\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained( \n",
        "    \"bert-base-uncased\", num_labels = classes_number, output_attentions = False, output_hidden_states = False)\n",
        "\n",
        "model.cuda()"
      ],
      "metadata": {
        "id": "Kx29Kr9byEmV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "019b63bd733f469b9ac0b54080b8d2af",
            "18f086a5619d4cf0b17a50ebcf5bd199",
            "a6a23ed51aad41f1a5187b1a9abe7ecf",
            "54e3bfb46e3b42ecbc716652f9b1ed1a",
            "e95fec3979f449f886bb64e9151b18b6",
            "e5c72932e5cd4216b9cee730d74de977",
            "b9d69cf021f641ada107f37ce95da1d7",
            "cda45d0d32424f04a8c276c09b760d36",
            "0a3bb70bf723443c83b147ef60a3b193",
            "166a1dd4a14b47eb910f435842a63f0d",
            "a90eabb3beb845b7b58850f7b2d370f8"
          ]
        },
        "outputId": "e5a27394-44ce-400a-f197-5921aaec917e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "019b63bd733f469b9ac0b54080b8d2af"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjlS0bpj9Wrl",
        "outputId": "ab715c49-a2c3-420c-c4e9-cb1205f9ff5c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Nov 14 02:26:44 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  A100-SXM4-40GB      Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   29C    P0    48W / 400W |   1682MiB / 40536MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamW(model.parameters(), lr = 2e-5, eps = 1e-8 )\n",
        "\n",
        "epochs = 4\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = total_steps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umd9G6H8yLmd",
        "outputId": "461beac9-509a-4652-ae17-c80ee7fb7da9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def flat_accuracy(preds1,labels):\n",
        "    pred_flat1 = np.argmax(preds1, axis=1).flatten()\n",
        "    labels = labels.flatten() \n",
        "    labels_flat1=np.asarray(labels)\n",
        "    acc1= np.sum(pred_flat1 == labels_flat1) / len(labels_flat1)\n",
        "    #return (acc1+acc2)/2\n",
        "    return acc1"
      ],
      "metadata": {
        "id": "yewC5MrPyNwE"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "metadata": {
        "id": "LLr9N5nhyPci"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    # Perform one full pass over the training set.\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # print(b_labels.shape)\n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "        result = model(b_input_ids, \n",
        "                       token_type_ids=None, \n",
        "                       attention_mask=b_input_mask, \n",
        "                       return_dict=True)\n",
        "        label1_preds = result[\"logits\"][:, :6]\n",
        "        label1_loss = torch.nn.functional.cross_entropy(label1_preds, b_labels[:, 0])\n",
        "\n",
        "\n",
        "        loss = label1_loss\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    total_eval_accuracy1 = 0\n",
        "    total_eval_accuracy2 = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        with torch.no_grad():        \n",
        "\n",
        "            result = model(b_input_ids, \n",
        "                           token_type_ids=None, \n",
        "                           attention_mask=b_input_mask,\n",
        "                           return_dict=True)\n",
        "\n",
        "        label1_preds = result[\"logits\"][:, :label_1_num_classes]\n",
        "        label1_loss = torch.nn.functional.cross_entropy(label1_preds, b_labels[:, 0])\n",
        "\n",
        "\n",
        "        loss = label1_loss \n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        label1_preds = label1_preds.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        eval_1 = flat_accuracy(label1_preds,label_ids)\n",
        "        total_eval_accuracy1+=eval_1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy1 = total_eval_accuracy1 / len(validation_dataloader)\n",
        "    print(\"  Accuracy1: {0:.2f}\".format(avg_val_accuracy1))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur. Label1.': avg_val_accuracy1,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n"
      ],
      "metadata": {
        "id": "388lbJ0xyPTQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ee5cb21-0f23-40d0-ae97-332e1fd9b434"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  1,125.    Elapsed: 0:00:31.\n",
            "  Batch    80  of  1,125.    Elapsed: 0:00:59.\n",
            "  Batch   120  of  1,125.    Elapsed: 0:01:27.\n",
            "  Batch   160  of  1,125.    Elapsed: 0:01:55.\n",
            "  Batch   200  of  1,125.    Elapsed: 0:02:23.\n",
            "  Batch   240  of  1,125.    Elapsed: 0:02:52.\n",
            "  Batch   280  of  1,125.    Elapsed: 0:03:20.\n",
            "  Batch   320  of  1,125.    Elapsed: 0:03:48.\n",
            "  Batch   360  of  1,125.    Elapsed: 0:04:16.\n",
            "  Batch   400  of  1,125.    Elapsed: 0:04:44.\n",
            "  Batch   440  of  1,125.    Elapsed: 0:05:12.\n",
            "  Batch   480  of  1,125.    Elapsed: 0:05:40.\n",
            "  Batch   520  of  1,125.    Elapsed: 0:06:09.\n",
            "  Batch   560  of  1,125.    Elapsed: 0:06:37.\n",
            "  Batch   600  of  1,125.    Elapsed: 0:07:05.\n",
            "  Batch   640  of  1,125.    Elapsed: 0:07:33.\n",
            "  Batch   680  of  1,125.    Elapsed: 0:08:01.\n",
            "  Batch   720  of  1,125.    Elapsed: 0:08:29.\n",
            "  Batch   760  of  1,125.    Elapsed: 0:08:58.\n",
            "  Batch   800  of  1,125.    Elapsed: 0:09:26.\n",
            "  Batch   840  of  1,125.    Elapsed: 0:09:54.\n",
            "  Batch   880  of  1,125.    Elapsed: 0:10:22.\n",
            "  Batch   920  of  1,125.    Elapsed: 0:10:50.\n",
            "  Batch   960  of  1,125.    Elapsed: 0:11:18.\n",
            "  Batch 1,000  of  1,125.    Elapsed: 0:11:46.\n",
            "  Batch 1,040  of  1,125.    Elapsed: 0:12:15.\n",
            "  Batch 1,080  of  1,125.    Elapsed: 0:12:43.\n",
            "  Batch 1,120  of  1,125.    Elapsed: 0:13:11.\n",
            "\n",
            "  Average training loss: 0.22\n",
            "  Training epcoh took: 0:13:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy1: 0.93\n",
            "  Validation Loss: 0.17\n",
            "  Validation took: 0:00:28\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  1,125.    Elapsed: 0:00:28.\n",
            "  Batch    80  of  1,125.    Elapsed: 0:00:56.\n",
            "  Batch   120  of  1,125.    Elapsed: 0:01:24.\n",
            "  Batch   160  of  1,125.    Elapsed: 0:01:53.\n",
            "  Batch   200  of  1,125.    Elapsed: 0:02:21.\n",
            "  Batch   240  of  1,125.    Elapsed: 0:02:49.\n",
            "  Batch   280  of  1,125.    Elapsed: 0:03:17.\n",
            "  Batch   320  of  1,125.    Elapsed: 0:03:45.\n",
            "  Batch   360  of  1,125.    Elapsed: 0:04:13.\n",
            "  Batch   400  of  1,125.    Elapsed: 0:04:42.\n",
            "  Batch   440  of  1,125.    Elapsed: 0:05:10.\n",
            "  Batch   480  of  1,125.    Elapsed: 0:05:38.\n",
            "  Batch   520  of  1,125.    Elapsed: 0:06:06.\n",
            "  Batch   560  of  1,125.    Elapsed: 0:06:34.\n",
            "  Batch   600  of  1,125.    Elapsed: 0:07:02.\n",
            "  Batch   640  of  1,125.    Elapsed: 0:07:31.\n",
            "  Batch   680  of  1,125.    Elapsed: 0:07:59.\n",
            "  Batch   720  of  1,125.    Elapsed: 0:08:27.\n",
            "  Batch   760  of  1,125.    Elapsed: 0:08:55.\n",
            "  Batch   800  of  1,125.    Elapsed: 0:09:23.\n",
            "  Batch   840  of  1,125.    Elapsed: 0:09:51.\n",
            "  Batch   880  of  1,125.    Elapsed: 0:10:19.\n",
            "  Batch   920  of  1,125.    Elapsed: 0:10:48.\n",
            "  Batch   960  of  1,125.    Elapsed: 0:11:16.\n",
            "  Batch 1,000  of  1,125.    Elapsed: 0:11:44.\n",
            "  Batch 1,040  of  1,125.    Elapsed: 0:12:12.\n",
            "  Batch 1,080  of  1,125.    Elapsed: 0:12:40.\n",
            "  Batch 1,120  of  1,125.    Elapsed: 0:13:08.\n",
            "\n",
            "  Average training loss: 0.12\n",
            "  Training epcoh took: 0:13:12\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy1: 0.94\n",
            "  Validation Loss: 0.20\n",
            "  Validation took: 0:00:28\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  1,125.    Elapsed: 0:00:28.\n",
            "  Batch    80  of  1,125.    Elapsed: 0:00:56.\n",
            "  Batch   120  of  1,125.    Elapsed: 0:01:25.\n",
            "  Batch   160  of  1,125.    Elapsed: 0:01:53.\n",
            "  Batch   200  of  1,125.    Elapsed: 0:02:21.\n",
            "  Batch   240  of  1,125.    Elapsed: 0:02:49.\n",
            "  Batch   280  of  1,125.    Elapsed: 0:03:17.\n",
            "  Batch   320  of  1,125.    Elapsed: 0:03:45.\n",
            "  Batch   360  of  1,125.    Elapsed: 0:04:14.\n",
            "  Batch   400  of  1,125.    Elapsed: 0:04:42.\n",
            "  Batch   440  of  1,125.    Elapsed: 0:05:10.\n",
            "  Batch   480  of  1,125.    Elapsed: 0:05:38.\n",
            "  Batch   520  of  1,125.    Elapsed: 0:06:06.\n",
            "  Batch   560  of  1,125.    Elapsed: 0:06:34.\n",
            "  Batch   600  of  1,125.    Elapsed: 0:07:03.\n",
            "  Batch   640  of  1,125.    Elapsed: 0:07:31.\n",
            "  Batch   680  of  1,125.    Elapsed: 0:07:59.\n",
            "  Batch   720  of  1,125.    Elapsed: 0:08:27.\n",
            "  Batch   760  of  1,125.    Elapsed: 0:08:55.\n",
            "  Batch   800  of  1,125.    Elapsed: 0:09:23.\n",
            "  Batch   840  of  1,125.    Elapsed: 0:09:52.\n",
            "  Batch   880  of  1,125.    Elapsed: 0:10:20.\n",
            "  Batch   920  of  1,125.    Elapsed: 0:10:48.\n",
            "  Batch   960  of  1,125.    Elapsed: 0:11:16.\n",
            "  Batch 1,000  of  1,125.    Elapsed: 0:11:44.\n",
            "  Batch 1,040  of  1,125.    Elapsed: 0:12:12.\n",
            "  Batch 1,080  of  1,125.    Elapsed: 0:12:41.\n",
            "  Batch 1,120  of  1,125.    Elapsed: 0:13:09.\n",
            "\n",
            "  Average training loss: 0.07\n",
            "  Training epcoh took: 0:13:12\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy1: 0.94\n",
            "  Validation Loss: 0.25\n",
            "  Validation took: 0:00:28\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  1,125.    Elapsed: 0:00:28.\n",
            "  Batch    80  of  1,125.    Elapsed: 0:00:56.\n",
            "  Batch   120  of  1,125.    Elapsed: 0:01:25.\n",
            "  Batch   160  of  1,125.    Elapsed: 0:01:53.\n",
            "  Batch   200  of  1,125.    Elapsed: 0:02:21.\n",
            "  Batch   240  of  1,125.    Elapsed: 0:02:49.\n",
            "  Batch   280  of  1,125.    Elapsed: 0:03:17.\n",
            "  Batch   320  of  1,125.    Elapsed: 0:03:45.\n",
            "  Batch   360  of  1,125.    Elapsed: 0:04:13.\n",
            "  Batch   400  of  1,125.    Elapsed: 0:04:42.\n",
            "  Batch   440  of  1,125.    Elapsed: 0:05:10.\n",
            "  Batch   480  of  1,125.    Elapsed: 0:05:38.\n",
            "  Batch   520  of  1,125.    Elapsed: 0:06:06.\n",
            "  Batch   560  of  1,125.    Elapsed: 0:06:34.\n",
            "  Batch   600  of  1,125.    Elapsed: 0:07:02.\n",
            "  Batch   640  of  1,125.    Elapsed: 0:07:31.\n",
            "  Batch   680  of  1,125.    Elapsed: 0:07:59.\n",
            "  Batch   720  of  1,125.    Elapsed: 0:08:27.\n",
            "  Batch   760  of  1,125.    Elapsed: 0:08:55.\n",
            "  Batch   800  of  1,125.    Elapsed: 0:09:23.\n",
            "  Batch   840  of  1,125.    Elapsed: 0:09:51.\n",
            "  Batch   880  of  1,125.    Elapsed: 0:10:19.\n",
            "  Batch   920  of  1,125.    Elapsed: 0:10:48.\n",
            "  Batch   960  of  1,125.    Elapsed: 0:11:16.\n",
            "  Batch 1,000  of  1,125.    Elapsed: 0:11:44.\n",
            "  Batch 1,040  of  1,125.    Elapsed: 0:12:12.\n",
            "  Batch 1,080  of  1,125.    Elapsed: 0:12:40.\n",
            "  Batch 1,120  of  1,125.    Elapsed: 0:13:08.\n",
            "\n",
            "  Average training loss: 0.04\n",
            "  Training epcoh took: 0:13:12\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy1: 0.94\n",
            "  Validation Loss: 0.28\n",
            "  Validation took: 0:00:28\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:54:43 (h:mm:ss)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculating testing accuracy."
      ],
      "metadata": {
        "id": "Qmt6gOJM1Tir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data={'sentence':X_test,'label':y_test}\n",
        "df=pd.DataFrame(data, columns =['label','sentence']) \n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values\n",
        "\n",
        "label_1_num_classes = classes_number\n",
        "\n",
        "# from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# label1_encoder = LabelEncoder()\n",
        "\n",
        "# label1 = [item[0] for item in labels]\n",
        "# label1 = label1_encoder.fit_transform(label1)\n",
        "\n",
        "label1 = torch.LongTensor(labels)\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for sent in sentences:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                sent,add_special_tokens = True,max_length = 512,pad_to_max_length = True, return_attention_mask = True,return_tensors = 'pt',)\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "all_labels = torch.stack([label1], dim=1)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, all_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, shuffle=False, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "_-15jhi61KOL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15a7dd65-3f3e-43d5-e1f2-6508bf7dfef3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of test sentences: 10,000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2310: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction on test set\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "accuracy1 = 0\n",
        "total_count = 0\n",
        "misclassify1=0\n",
        "misclassify_data=[]\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict\n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions.\n",
        "      result = model(b_input_ids, \n",
        "                     token_type_ids=None, \n",
        "                     attention_mask=b_input_mask,\n",
        "                     return_dict=True)\n",
        "\n",
        "  #logits = result.logits\n",
        "  label1_preds = result[\"logits\"][:, :label_1_num_classes]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  label1_preds = label1_preds.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "  label1_preds=np.argmax(label1_preds,axis=1)\n",
        "  label_ids = label_ids.flatten()\n",
        "\n",
        "  for i in range(len(label_ids)):\n",
        "    if(label1_preds[i]==label_ids[i]):\n",
        "      accuracy1+=1\n",
        "    else:\n",
        "      misclassify1+=1\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print(\"Number of Label1 correctly predicted: \"+str(accuracy1))\n",
        "print(\"Number of Label1 misclassify: \"+str(misclassify1))\n",
        "\n",
        "print(\"Label1 Testing Accuracy: {:.2f}\".format(accuracy1/(accuracy1+misclassify1) ) )\n",
        "bert_singlelabel_accuracy1 = accuracy1/(accuracy1+misclassify1)"
      ],
      "metadata": {
        "id": "U9RkqHLt1ZBe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c97b1a4-7aa9-463c-8d84-c5ddb8a3550a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels for 10,000 test sentences...\n",
            "\n",
            "Number of Label1 correctly predicted: 9427\n",
            "Number of Label1 misclassify: 573\n",
            "Label1 Testing Accuracy: 0.94\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pz36NxcFMAEC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}